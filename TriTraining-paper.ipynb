{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriTraining:\n",
    "    def __init__(self, classifiers):\n",
    "        self.classifier = classifiers\n",
    "    \n",
    "    def train(self, L_X, L_y, U_X, X_test, y_test):\n",
    "        try:\n",
    "            if len(self.classifier) == 3:#if input 3 models, use them for tritraining\n",
    "                self.classifiers = [sklearn.base.clone(self.classifier[i]) for i in range(3)]\n",
    "                for i in range(3):\n",
    "                    self.classifiers[i].fit(L_X, L_y)\n",
    "        except TypeError as e:#if input 1 model, clone it three times\n",
    "            self.classifiers = [sklearn.base.clone(self.classifier) for i in range(3)]\n",
    "            sample = sklearn.utils.resample(L_X, L_y)\n",
    "            for i in range(3):\n",
    "                self.classifiers[i].fit(*sample)\n",
    "            \n",
    "        self.init_score = self.score(X_test, y_test)\n",
    "        self.fit(L_X, L_y, U_X)\n",
    "        return self.score(X_test, y_test)\n",
    "        \n",
    "    def fit(self, L_X, L_y, U_X):\n",
    "        e_prime = [0.5]*3\n",
    "        l_prime = [0]*3\n",
    "        e = [0]*3\n",
    "        update = [False]*3\n",
    "        Li_X, Li_y = [[]]*3, [[]]*3#to save proxy labeled data\n",
    "        improve = True\n",
    "        self.iter = 0\n",
    "        \n",
    "        while improve:\n",
    "            self.iter += 1#count iterations \n",
    "            \n",
    "            for i in range(3):    \n",
    "                j, k = np.delete(np.array([0,1,2]),i)\n",
    "                update[i] = False\n",
    "                e[i] = self.measure_error(L_X, L_y, j, k)\n",
    "                if e[i] < e_prime[i]:\n",
    "                    U_y_j = self.classifiers[j].predict(U_data)\n",
    "                    U_y_k = self.classifiers[k].predict(U_data)\n",
    "                    Li_X[i] = U_X[U_y_j == U_y_k]#when two models agree on the label, save it\n",
    "                    Li_y[i] = U_y_j[U_y_j == U_y_k]\n",
    "                    if l_prime[i] == 0:#no updated before\n",
    "                        l_prime[i]  = int(e[i]/(e_prime[i] - e[i]) + 1)\n",
    "                    if l_prime[i] <len(Li_y[i]):\n",
    "                        if e[i]*len(Li_y[i])<e_prime[i] * l_prime[i]:\n",
    "                            update[i] = True\n",
    "                        elif l_prime[i] > e[i]/(e_prime[i] - e[i]):\n",
    "                            L_index = np.random.choice(len(Li_y[i]), int(e_prime[i] * l_prime[i]/e[i] -1))#subsample from proxy labeled data\n",
    "                            Li_X[i], Li_y[i] = Li_X[i][L_index], Li_y[i][L_index]\n",
    "                            update[i] = True\n",
    "             \n",
    "            for i in range(3):\n",
    "                if update[i]:\n",
    "                    self.classifiers[i].fit(np.append(L_X,Li_X[i],axis=0), np.append(L_y, Li_y[i], axis=0))#train the classifier on integrated dataset\n",
    "                    e_prime[i] = e[i]\n",
    "                    l_prime[i] = len(Li_y[i])\n",
    "    \n",
    "            if update == [False]*3:\n",
    "                improve = False#if no classifier was updated, no improvement\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = np.asarray([self.classifiers[i].predict(X) for i in range(3)])\n",
    "        pred[0][pred[1]==pred[2]] = pred[1][pred[1]==pred[2]]\n",
    "        return pred[0]\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        return sklearn.metrics.accuracy_score(y, self.predict(X))\n",
    "        \n",
    "    def measure_error(self, X, y, j, k):\n",
    "        j_pred = self.classifiers[j].predict(X)\n",
    "        k_pred = self.classifiers[k].predict(X)\n",
    "        wrong_index =np.logical_and(j_pred != y, k_pred==j_pred)#model_j and model_k make the same wrong prediction\n",
    "        #wrong_index =np.logical_and(j_pred != y_test, k_pred!=y_test)\n",
    "        return sum(wrong_index)/sum(j_pred == k_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203,)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(U_data.shape[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.832369942197 0.797687861272\n"
     ]
    }
   ],
   "source": [
    "L_data, L_label, U_data, X_test, y_test = data_process(dataset['australian']['X'], dataset['australian']['y'], 0.6)\n",
    "# U_label = np.zeros([U_data.shape[0]])\n",
    "# X_train = np.concatenate((L_data, U_data))\n",
    "# y_train = np.concatenate((\n",
    "#             L_label.astype(str),\n",
    "#             np.full_like(U_label.astype(str), \"unlabeled\")\n",
    "#         ))\n",
    "# m = StandardSelfTraining('s', classifier['DecisionTree'])\n",
    "# m.fit(X_train, y_train)\n",
    "# print(m.score(X_test, y_test))\n",
    "m1 = SelfTraining1(classifier['DecisionTree'])\n",
    "print(m1.train(L_data, L_label, U_data, X_test, y_test, 0.6), m1.init_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfTraining1:\n",
    "    def __init__(self, classifiers):\n",
    "        self.classifier = classifiers\n",
    "        \n",
    "    def train(self, L_X, L_y, U_X, X_test, y_test, tau):\n",
    "        try:\n",
    "            if len(self.classifier) == 3:#if input 3 models, use them for tritraining\n",
    "                self.classifiers = [sklearn.base.clone(self.classifier[i]) for i in range(3)]\n",
    "                for i in range(3):\n",
    "                    self.classifiers[i].fit(L_X, L_y)\n",
    "        except TypeError as e:#if input 1 model, clone it three times\n",
    "            self.classifiers = [sklearn.base.clone(self.classifier) for i in range(3)]\n",
    "            sample = sklearn.utils.resample(L_X, L_y)\n",
    "            for i in range(3):\n",
    "                self.classifiers[i].fit(*sample)\n",
    "            \n",
    "        self.init_score = self.score(X_test, y_test)\n",
    "        self.fit(L_X, L_y, U_X, tau)\n",
    "        return self.score(X_test, y_test)\n",
    "    \n",
    "    def fit(self, L_X, L_y, U_X, tau):\n",
    "        for c in range(3):\n",
    "            improve =  True\n",
    "            self.iter = 0\n",
    "            while improve and len(U_X)!=0:\n",
    "                self.classifiers[c].fit(L_X, L_y)\n",
    "                U_prob = self.classifiers[c].predict_proba(U_X)\n",
    "                U_label = self.classifiers[c].predict(U_X)\n",
    "                label_index = np.argmax(U_prob, axis = 1)>tau\n",
    "\n",
    "                if sum(label_index) ==0:\n",
    "                    improve = False\n",
    "                self.iter += 1\n",
    "                L_X = np.append(L_X, U_X[label_index], axis=0)\n",
    "                L_y = np.append(L_y, U_label[label_index])\n",
    "                U_X = np.delete(U_X, np.where(label_index), axis=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = np.asarray([self.classifiers[i].predict(X) for i in range(3)])\n",
    "        pred[0][pred[1]==pred[2]] = pred[1][pred[1]==pred[2]]\n",
    "        return pred[0]\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        return sklearn.metrics.accuracy_score(y, self.predict(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfTraining2:\n",
    "    def __init__(self, classifiers):\n",
    "        self.classifier = classifiers\n",
    "    \n",
    "    def train(self, L_X, L_y, U_X, X_test, y_test):\n",
    "        try:\n",
    "            if len(self.classifier) == 3:#if input 3 models, use them for tritraining\n",
    "                self.classifiers = [sklearn.base.clone(self.classifier[i]) for i in range(3)]\n",
    "                for i in range(3):\n",
    "                    self.classifiers[i].fit(L_X, L_y)\n",
    "        except TypeError as e:#if input 1 model, clone it three times\n",
    "            self.classifiers = [sklearn.base.clone(self.classifier) for i in range(3)]\n",
    "            sample = sklearn.utils.resample(L_X, L_y)\n",
    "            for i in range(3):\n",
    "                self.classifiers[i].fit(*sample)\n",
    "            \n",
    "        self.init_score = self.score(X_test, y_test)\n",
    "        self.fit(L_X, L_y, U_X)\n",
    "        return self.score(X_test, y_test)\n",
    "        \n",
    "    def fit(self, L_X, L_y, U_X):\n",
    "        e_prime = [0.5]*3\n",
    "        l_prime = [0]*3\n",
    "        e = [0]*3\n",
    "        update = [False]*3\n",
    "        Li_X, Li_y = [[]]*3, [[]]*3#to save proxy labeled data\n",
    "        improve = True\n",
    "        self.iter = 0\n",
    "        \n",
    "        while improve:\n",
    "            self.iter += 1#count iterations \n",
    "            \n",
    "            for i in range(3):    \n",
    "                j, k = np.delete(np.array([0,1,2]),i)\n",
    "                update[i] = False\n",
    "                e[i] = self.measure_error(L_X, L_y, j, k)\n",
    "                if e[i] < e_prime[i]:\n",
    "                    U_y_j = self.classifiers[j].predict(U_data)\n",
    "                    U_y_k = self.classifiers[k].predict(U_data)\n",
    "                    Li_X[i] = U_X[U_y_j == U_y_k]#when two models agree on the label, save it\n",
    "                    Li_y[i] = U_y_j[U_y_j == U_y_k]\n",
    "                    if l_prime[i] == 0:#no updated before\n",
    "                        l_prime[i]  = int(e[i]/(e_prime[i] - e[i]) + 1)\n",
    "                    if l_prime[i] <len(Li_y[i]):\n",
    "                        if e[i]*len(Li_y[i])<e_prime[i] * l_prime[i]:\n",
    "                            update[i] = True\n",
    "                        elif l_prime[i] > e[i]/(e_prime[i] - e[i]):\n",
    "                            L_index = np.random.choice(len(Li_y[i]), int(e_prime[i] * l_prime[i]/e[i] -1))#subsample from proxy labeled data\n",
    "                            Li_X[i], Li_y[i] = Li_X[i][L_index], Li_y[i][L_index]\n",
    "                            update[i] = True\n",
    "             \n",
    "            for i in range(3):\n",
    "                if update[i]:\n",
    "                    self.classifiers[i].fit(np.append(L_X,Li_X[i],axis=0), np.append(L_y, Li_y[i], axis=0))#train the classifier on integrated dataset\n",
    "                    e_prime[i] = e[i]\n",
    "                    l_prime[i] = len(Li_y[i])\n",
    "    \n",
    "            if update == [False]*3:\n",
    "                improve = False#if no classifier was updated, no improvement\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.classifiers[0].predict(X)\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        return sklearn.metrics.accuracy_score(y, self.predict(X))\n",
    "        \n",
    "    def measure_error(self, X, y, j, k):\n",
    "        j_pred = self.classifiers[j].predict(X)\n",
    "        k_pred = self.classifiers[k].predict(X)\n",
    "        wrong_index =np.logical_and(j_pred != y, k_pred==j_pred)#model_j and model_k make the same wrong prediction\n",
    "        #wrong_index =np.logical_and(j_pred != y_test, k_pred!=y_test)\n",
    "        return sum(wrong_index)/sum(j_pred == k_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriTrainingwDisagreement():\n",
    "\n",
    "    def __init__(self, classifier):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            classifier - classifier, with .train, .predict API (refer to classifiers of sklearn)\n",
    "        \"\"\"\n",
    "        # Initialize\n",
    "        self.clf = [sklearn.base.clone(classifier) for i in range(3)]\n",
    "\n",
    "    def measure_error(self, j, k):\n",
    "        \"\"\"\n",
    "        args:\n",
    "                j - int, classifier index\n",
    "                k - int, classifier index\n",
    "        return:\n",
    "                float, classification_error\n",
    "        \"\"\"\n",
    "        y_predict_j = self.clf[j].predict(self.X_label)\n",
    "        y_predict_k = self.clf[k].predict(self.X_label)\n",
    "        return (1 - np.sum((y_predict_j == y_predict_k) & (y_predict_j == self.y_label)) / np.sum(y_predict_j == y_predict_k))\n",
    "\n",
    "    def fit(self, X_label, y_label, X_unlabel):\n",
    "        \"\"\"\n",
    "        args:\n",
    "                X_label - labeled train feature vector (ndarray of size, # of samples * # of features), features are numeric numbers\n",
    "                y_label - labeled train label vector (ndarray of size, # of samples), labels are numeric numbers\n",
    "                X_unlabel - test feature vector (ndarray of size, # of samples * # of features), features are numeric numbers\n",
    "        \"\"\"        \n",
    "\n",
    "        self.X_label = X_label\n",
    "        self.y_label = y_label\n",
    "\n",
    "        classification_error_current = [0.5, 0.5, 0.5]\n",
    "        classification_error = [0.5, 0.5, 0.5]\n",
    "        pseudo_label_size_current = [0, 0, 0]\n",
    "        pseudo_label_size = [0, 0, 0]\n",
    "        # pseudo_label_index used to compare and check if tri-training can be stopped, when two iterations have the same label_index, means tri-training can be stopped\n",
    "        X_pseudo_label_index = [[], [], []]\n",
    "        X_pseudo_label_index_current = [[], [], []]\n",
    "\n",
    "        feature_size = self.X_label.shape[1]\n",
    "\n",
    "        # Train each classifier with bootstrampped subset\n",
    "        for i in range(3):\n",
    "            X_resample, y_resample = sklearn.utils.resample(self.X_label, self.y_label)  # BootstrapSample(L)\n",
    "            self.clf[i].fit(X_resample, y_resample)  # Learn(Si)\n",
    "\n",
    "        iteration = 0\n",
    "        while (True):\n",
    "\n",
    "            update = [False, False, False]\n",
    "\n",
    "            iteration = iteration + 1\n",
    "            for i in range(3):\n",
    "                X_pseudo_label_index_current[i] = X_pseudo_label_index[i]\n",
    "\n",
    "            # Step3.1 Set Li = empty set, Li denotes the new pseudo label set determined by tri-training iteration for classifier i\n",
    "            # X_pseudo_label_index, contains the data record index (in the full unlabelled set) of the new pseudo label set determined by tri-training iteration for classifier i\n",
    "            # X_pseudo_label, contains the features for new pseudo label set determined by tri-training iteration for classifier i\n",
    "            # y_pseudo_label, contains the labels (not ground truth label, but pseudo label calculated by tri-training iteration) for new pseudo label set determined by tri-training iteration for classifier i\n",
    "            X_pseudo_label_index = [[], [], []]\n",
    "            X_pseudo_label = [[], [], []]\n",
    "            y_pseudo_label = [[], [], []]\n",
    "\n",
    "            # Step 3.2 Loop through all the data record in unlabelled set\n",
    "            for i in range(3):\n",
    "                j, k = np.delete(np.array([0, 1, 2]), i)\n",
    "                classification_error[i] = self.measure_error(j, k)\n",
    "                if classification_error[i] < classification_error_current[i]:\n",
    "                    # Step 3.2 If classifier j,k aggrees with the label for one data record, and not agree with classifier i, in unlabelled set,\n",
    "                    # then add the data record into Li                    \n",
    "                    y_predict_j = self.clf[j].predict(X_unlabel)\n",
    "                    y_predict_k = self.clf[k].predict(X_unlabel)\n",
    "                    y_predict_i = self.clf[i].predict(X_unlabel)\n",
    "                    y_pseudo_label[i] = y_predict_j[np.logical_and(y_predict_j==y_predict_k,y_predict_j!=y_predict_i)]\n",
    "                    X_pseudo_label_index[i] = np.where(np.logical_and(y_predict_j==y_predict_k,y_predict_j!=y_predict_i))\n",
    "                    \n",
    "                    pseudo_label_size[i] = len(X_pseudo_label_index[i])\n",
    "                    #print(\"classification_error: {}, classification_error_current: {}, pseudo_label_size: {}, pseudo_label_size_current: {}\".format(classification_error[i], classification_error_current[i], pseudo_label_size[i],pseudo_label_size_current[i]))\n",
    "\n",
    "                    if pseudo_label_size_current[i] == 0:\n",
    "                        pseudo_label_size_current[i] = math.floor(classification_error[i] / (classification_error_current[i] - classification_error[i]) + 1)\n",
    "                    if pseudo_label_size_current[i] < pseudo_label_size[i]:\n",
    "                        if ((classification_error[i] * pseudo_label_size[i]) < (classification_error_current[i] * pseudo_label_size_current[i])):\n",
    "                            update[i] = True\n",
    "                        elif pseudo_label_size_current[i] > (classification_error[i] / (classification_error_current[i] - classification_error[i])):\n",
    "                            resample_size = math.ceil(classification_error_current[i] * pseudo_label_size_current[i] / classification_error[i] - 1)\n",
    "                            X_pseudo_label_index[i], y_pseudo_label[i] = sklearn.utils.resample(X_pseudo_label_index[i],y_pseudo_label[i],replace=False,n_samples=resample_size)\n",
    "                            pseudo_label_size[i] = len(X_pseudo_label_index[i])\n",
    "                            update[i] = True\n",
    "\n",
    "            # Step 3.3 Train all the three classifiers with Li + original labelled data set\n",
    "            for i in range(3):\n",
    "                if update[i] == True:\n",
    "                    #print(\"number of pseudo labels added for classifier {} is: {}\".format(i,len(X_pseudo_label_index[i])))\n",
    "                    X_pseudo_label[i] = np.array(X_unlabel[X_pseudo_label_index[i]])\n",
    "                    self.clf[i].fit(np.concatenate((X_pseudo_label[i], self.X_label), axis=0),np.concatenate((np.array(y_pseudo_label[i]), self.y_label), axis=0))\n",
    "                    classification_error_current[i] = classification_error[i]\n",
    "                    pseudo_label_size_current[i] = pseudo_label_size[i]\n",
    "\n",
    "            # Stop tri-training process, if the pseudo label data set added in current tri-training iteration\n",
    "            # is the same for last tri-training iteration for all classifiers\n",
    "            if (np.array_equal(X_pseudo_label_index[0], X_pseudo_label_index_current[0]) & np.array_equal(X_pseudo_label_index[1], X_pseudo_label_index_current[1]) \n",
    "                    & np.array_equal(X_pseudo_label_index[2], X_pseudo_label_index_current[2])):\n",
    "                break\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        args:\n",
    "                X_test - test feature vector (ndarray of size, # of samples * # of features), features are numeric numbers\n",
    "        return:\n",
    "                array of size (# of test samples), with values as predicted label 1 or 0\n",
    "        \"\"\"\n",
    "        I = self.clf[0].predict(X_test)\n",
    "        J = self.clf[1].predict(X_test)\n",
    "        K = self.clf[2].predict(X_test)\n",
    "        I[J == K] = J[J == K]\n",
    "        return I\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        args:\n",
    "                X_test - test feature vector (ndarray of size, # of samples * # of features), features are numeric numbers\n",
    "                y_test - test label vector (ndarray of size, # of samples), labels are numeric numbers\n",
    "        return:\n",
    "                float, accuracy_score of predicted value by the tri-training (with disagreement) classifier against groud truth\n",
    "        \"\"\"\n",
    "        \n",
    "        return sklearn.metrics.accuracy_score(y_test, self.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(data, label, rate, test_rate=0.25):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size = test_rate, random_state=0)\n",
    "\n",
    "    rng = np.random.RandomState(0)#to make same index every time\n",
    "    labeled_index = rng.rand(len(y_train)) < rate#in training set, choose 20% as labeled data\n",
    "    unlabeled_index = np.logical_not(labeled_index)\n",
    "    L_data = X_train[labeled_index]#data of L\n",
    "    L_label = y_train[labeled_index]#lable of L\n",
    "    U_data = X_train[unlabeled_index]#data of U\n",
    "    return L_data, L_label, U_data, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = {}\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier['DecisionTree'] = tree.DecisionTreeClassifier()\n",
    "classifier['BP_Network'] = MLPClassifier(solver='lbfgs', alpha=1e-3, hidden_layer_sizes=(20, 10), random_state=1)\n",
    "classifier['NaiveBayes'] = GaussianNB()\n",
    "# classifier['KNN'] = KNeighborsClassifier(\n",
    "#         n_neighbors=3,\n",
    "#         metric=\"euclidean\",\n",
    "#         #n_jobs=2  # Parallelize work on CPUs\n",
    "#     )\n",
    "# classifier['SGD'] = linear_model.SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "# classifier['SVM'] = svm.SVC(gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dataset = {}\n",
    "\n",
    "data = np.loadtxt('australian.dat')[:, 0:14]\n",
    "label = np.loadtxt('australian.dat')[:, 14]\n",
    "dataset['australian'] = {'X': data, 'y':label}\n",
    "\n",
    "data = np.loadtxt('ionosphere.data', delimiter=',')[:, 0:34]\n",
    "label = np.loadtxt('ionosphere.data', delimiter=',')[:, 34]\n",
    "dataset['ionosphere'] = {'X': data, 'y':label}\n",
    "\n",
    "data = np.loadtxt('wdbc.data', delimiter=',')[:, 2:34]\n",
    "label = np.loadtxt('wdbc.data', delimiter=',')[:, 1]\n",
    "dataset['wdbc'] = {'X': data, 'y':label}\n",
    "\n",
    "data = np.loadtxt('bupa.data', delimiter=',')[:, :6]\n",
    "label = np.loadtxt('bupa.data', delimiter=',')[:, 6]\n",
    "dataset['bupa'] = {'X': data, 'y': label}\n",
    "\n",
    "data = np.loadtxt('german.data-numeric')[:, 0:20]\n",
    "label = np.loadtxt('german.data-numeric')[:, 20]\n",
    "dataset['german'] = {'X': data, 'y': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.base.is_classifier(classifiers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree\n",
      "BP_Network\n",
      "[GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(20, 10), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.060000000000000053"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_data, L_label, U_data, X_test, y_test = data_process(dataset[d]['X'], dataset[d]['y'], r)\n",
    "\n",
    "classifiers = [sklearn.base.clone(classifier[c])]\n",
    "for clf in classifier.keys():\n",
    "    if clf != c:\n",
    "        print(clf)\n",
    "        classifiers.append(sklearn.base.clone(classifier[clf]))#use the first clf in classifiers to output score, but all three to label data\n",
    "print(classifiers)\n",
    "m = TriTraining(classifiers)\n",
    "1 - m.train(L_data, L_label, U_data, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: australian (690, 14)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.2\n",
      "dataset: australian (690, 14)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.4\n",
      "dataset: australian (690, 14)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.6\n",
      "dataset: australian (690, 14)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.8\n",
      "dataset: australian (690, 14)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.2\n",
      "dataset: australian (690, 14)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.4\n",
      "dataset: australian (690, 14)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.6\n",
      "dataset: australian (690, 14)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.8\n",
      "dataset: australian (690, 14)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.2\n",
      "dataset: australian (690, 14)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.4\n",
      "dataset: australian (690, 14)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.6\n",
      "dataset: australian (690, 14)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.8\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.2\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.4\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.6\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.8\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.2\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.4\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.6\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.8\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.2\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.4\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.6\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.8\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.2\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.4\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.6\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.8\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.2\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.4\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.6\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.8\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.2\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.4\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.6\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.8\n",
      "dataset: bupa (345, 6)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.2\n",
      "dataset: bupa (345, 6)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.4\n",
      "dataset: bupa (345, 6)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.6\n",
      "dataset: bupa (345, 6)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.8\n",
      "dataset: bupa (345, 6)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.2\n",
      "dataset: bupa (345, 6)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.4\n",
      "dataset: bupa (345, 6)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.6\n",
      "dataset: bupa (345, 6)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.8\n",
      "dataset: bupa (345, 6)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.2\n",
      "dataset: bupa (345, 6)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.4\n",
      "dataset: bupa (345, 6)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.6\n",
      "dataset: bupa (345, 6)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.8\n",
      "dataset: german (1000, 20)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.2\n",
      "dataset: german (1000, 20)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.4\n",
      "dataset: german (1000, 20)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.6\n",
      "dataset: german (1000, 20)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.8\n",
      "dataset: german (1000, 20)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.2\n",
      "dataset: german (1000, 20)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.4\n",
      "dataset: german (1000, 20)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.6\n",
      "dataset: german (1000, 20)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.8\n",
      "dataset: german (1000, 20)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.2\n",
      "dataset: german (1000, 20)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.4\n",
      "dataset: german (1000, 20)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.6\n",
      "dataset: german (1000, 20)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.8\n"
     ]
    }
   ],
   "source": [
    "results = None\n",
    "\n",
    "for d in dataset:\n",
    "    for c in classifier:\n",
    "        for r in [0.2, 0.4, 0.6, 0.8]:        \n",
    "            print('dataset:', d, dataset[d]['X'].shape)\n",
    "            print('classifier:', c)\n",
    "            print('label_rate:', r)\n",
    "            error = np.zeros([4,50])\n",
    "            init_error = np.zeros([3,50])\n",
    "            for i in range(50):#average on 20 data splits\n",
    "                L_data, L_label, U_data, X_test, y_test = data_process(dataset[d]['X'], dataset[d]['y'], r)\n",
    "                \n",
    "                classifiers = [sklearn.base.clone(classifier[c])]\n",
    "                \n",
    "                for clf in classifier.keys():\n",
    "                    if clf != c:\n",
    "                        classifiers.append(sklearn.base.clone(classifier[clf]))#use the first clf in classifiers to output score, but all three to label data\n",
    "                m = TriTraining(classifier[c])\n",
    "                error[0,i] = 1 - m.train(L_data, L_label, U_data, X_test, y_test)\n",
    "                init_error[0,i] = 1- m.init_score\n",
    "                \n",
    "#                 m2 = TriTrainingwDisagreement(classifier[c])\n",
    "#                 m2.fit(L_data, L_label, U_data)\n",
    "#                 error[1, i] = 1-m2.score(X_test, y_test)\n",
    "                m2 = SelfTraining1(classifier[c])\n",
    "                error[1,i] = 1 - m2.train(L_data, L_label, U_data, X_test, y_test, 0.7)\n",
    "                init_error[1,i] = 1- m2.init_score\n",
    "            \n",
    "                m3 = SelfTraining2(classifier[c])\n",
    "                error[2,i] = 1 - m3.train(L_data, L_label, U_data, X_test, y_test)\n",
    "                init_error[2,i] = 1- m3.init_score\n",
    "                \n",
    "                m4 = sklearn.base.clone(classifier[c])\n",
    "                m4.fit(L_data, L_label)\n",
    "                error[3,i] = 1 - m4.score(X_test, y_test)\n",
    "                \n",
    "            e = np.mean(error, axis = 1)\n",
    "            init_e = np.mean(init_error, axis = 1)\n",
    "#             print('TriTraining test error', e[0])\n",
    "#             print('TriTraining Disagree test error', e[1])\n",
    "#             print('SelfTraining test error', e[2])\n",
    "#             print('Supervised test error', e[3],'\\n')\n",
    "            \n",
    "            test_info = {'dataset': d+str(dataset[d]['X'].shape), 'classifier': c, 'label_rate': r}\n",
    "            errors = {'TriTraining': e[0], 'SelfTraining1': e[1],'SelfTraining2': e[2], 'Supervised': e[3], 'TriTraining_init': init_e[0], 'SelfTraining1_init': init_e[1], 'SelfTraining2_init': init_e[2]}#, 'Best': methods[np.argmin(e)]}#'\n",
    "            if results is None:\n",
    "                results = pd.DataFrame([{**test_info, **errors}])\n",
    "            else:\n",
    "                results.loc[len(results.index)] = {**test_info, **errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SelfTraining1</th>\n",
       "      <th>SelfTraining1_init</th>\n",
       "      <th>SelfTraining2</th>\n",
       "      <th>SelfTraining2_init</th>\n",
       "      <th>Supervised</th>\n",
       "      <th>TriTraining</th>\n",
       "      <th>TriTraining_init</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_rate</th>\n",
       "      <th>dataset</th>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">0.2</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">australian(690, 14)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.359538</td>\n",
       "      <td>0.359538</td>\n",
       "      <td>0.344624</td>\n",
       "      <td>0.356994</td>\n",
       "      <td>0.323699</td>\n",
       "      <td>0.347283</td>\n",
       "      <td>0.382081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.160231</td>\n",
       "      <td>0.178150</td>\n",
       "      <td>0.175029</td>\n",
       "      <td>0.177457</td>\n",
       "      <td>0.177457</td>\n",
       "      <td>0.169942</td>\n",
       "      <td>0.177341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.179191</td>\n",
       "      <td>0.184740</td>\n",
       "      <td>0.187630</td>\n",
       "      <td>0.173410</td>\n",
       "      <td>0.184971</td>\n",
       "      <td>0.187514</td>\n",
       "      <td>0.183353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">bupa(345, 6)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.464368</td>\n",
       "      <td>0.464368</td>\n",
       "      <td>0.446437</td>\n",
       "      <td>0.456552</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.445977</td>\n",
       "      <td>0.452644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.354943</td>\n",
       "      <td>0.417471</td>\n",
       "      <td>0.387126</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.378161</td>\n",
       "      <td>0.388736</td>\n",
       "      <td>0.432644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.471264</td>\n",
       "      <td>0.445747</td>\n",
       "      <td>0.462759</td>\n",
       "      <td>0.443218</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.457701</td>\n",
       "      <td>0.452414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">german(1000, 20)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.200720</td>\n",
       "      <td>0.143680</td>\n",
       "      <td>0.209360</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.140640</td>\n",
       "      <td>0.205680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.041440</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.042480</td>\n",
       "      <td>0.029920</td>\n",
       "      <td>0.038560</td>\n",
       "      <td>0.039600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.129920</td>\n",
       "      <td>0.165040</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.098160</td>\n",
       "      <td>0.124800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ionosphere(351, 34)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.245455</td>\n",
       "      <td>0.266364</td>\n",
       "      <td>0.252727</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.255909</td>\n",
       "      <td>0.248636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.164091</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.186591</td>\n",
       "      <td>0.234091</td>\n",
       "      <td>0.211818</td>\n",
       "      <td>0.166364</td>\n",
       "      <td>0.222727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.193182</td>\n",
       "      <td>0.143409</td>\n",
       "      <td>0.134318</td>\n",
       "      <td>0.142273</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.132955</td>\n",
       "      <td>0.138636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">wdbc(569, 30)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.125874</td>\n",
       "      <td>0.092028</td>\n",
       "      <td>0.081818</td>\n",
       "      <td>0.095804</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.081259</td>\n",
       "      <td>0.097203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.157902</td>\n",
       "      <td>0.106294</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.099441</td>\n",
       "      <td>0.107972</td>\n",
       "      <td>0.084056</td>\n",
       "      <td>0.096224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.067273</td>\n",
       "      <td>0.074965</td>\n",
       "      <td>0.068252</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.075944</td>\n",
       "      <td>0.067552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">0.4</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">australian(690, 14)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.543353</td>\n",
       "      <td>0.333064</td>\n",
       "      <td>0.451908</td>\n",
       "      <td>0.321040</td>\n",
       "      <td>0.236994</td>\n",
       "      <td>0.465549</td>\n",
       "      <td>0.324624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.186705</td>\n",
       "      <td>0.201503</td>\n",
       "      <td>0.180462</td>\n",
       "      <td>0.197919</td>\n",
       "      <td>0.183815</td>\n",
       "      <td>0.174335</td>\n",
       "      <td>0.198613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.213873</td>\n",
       "      <td>0.236763</td>\n",
       "      <td>0.265896</td>\n",
       "      <td>0.240231</td>\n",
       "      <td>0.265896</td>\n",
       "      <td>0.265896</td>\n",
       "      <td>0.236301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">bupa(345, 6)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.394253</td>\n",
       "      <td>0.387816</td>\n",
       "      <td>0.410575</td>\n",
       "      <td>0.367816</td>\n",
       "      <td>0.380460</td>\n",
       "      <td>0.386667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.354253</td>\n",
       "      <td>0.396092</td>\n",
       "      <td>0.386437</td>\n",
       "      <td>0.414943</td>\n",
       "      <td>0.354713</td>\n",
       "      <td>0.371724</td>\n",
       "      <td>0.391724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.449425</td>\n",
       "      <td>0.470805</td>\n",
       "      <td>0.455862</td>\n",
       "      <td>0.471264</td>\n",
       "      <td>0.471494</td>\n",
       "      <td>0.452414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">german(1000, 20)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.126400</td>\n",
       "      <td>0.091280</td>\n",
       "      <td>0.135760</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.084400</td>\n",
       "      <td>0.132880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.038560</td>\n",
       "      <td>0.042240</td>\n",
       "      <td>0.039760</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.038160</td>\n",
       "      <td>0.041920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.110960</td>\n",
       "      <td>0.107840</td>\n",
       "      <td>0.108960</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.107040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ionosphere(351, 34)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.102045</td>\n",
       "      <td>0.140227</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.099091</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.042955</td>\n",
       "      <td>0.112273</td>\n",
       "      <td>0.069773</td>\n",
       "      <td>0.119318</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.067273</td>\n",
       "      <td>0.107273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.102273</td>\n",
       "      <td>0.086591</td>\n",
       "      <td>0.069773</td>\n",
       "      <td>0.086591</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.067955</td>\n",
       "      <td>0.087273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">wdbc(569, 30)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.104895</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.069650</td>\n",
       "      <td>0.079301</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.064755</td>\n",
       "      <td>0.079860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.086713</td>\n",
       "      <td>0.082098</td>\n",
       "      <td>0.058601</td>\n",
       "      <td>0.085035</td>\n",
       "      <td>0.056503</td>\n",
       "      <td>0.057203</td>\n",
       "      <td>0.086014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.058601</td>\n",
       "      <td>0.060280</td>\n",
       "      <td>0.061259</td>\n",
       "      <td>0.055944</td>\n",
       "      <td>0.059021</td>\n",
       "      <td>0.058042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">0.6</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">australian(690, 14)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.300578</td>\n",
       "      <td>0.282312</td>\n",
       "      <td>0.259538</td>\n",
       "      <td>0.276763</td>\n",
       "      <td>0.289017</td>\n",
       "      <td>0.250289</td>\n",
       "      <td>0.284509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.179769</td>\n",
       "      <td>0.159306</td>\n",
       "      <td>0.178844</td>\n",
       "      <td>0.153988</td>\n",
       "      <td>0.156647</td>\n",
       "      <td>0.176301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.202312</td>\n",
       "      <td>0.229480</td>\n",
       "      <td>0.217919</td>\n",
       "      <td>0.218728</td>\n",
       "      <td>0.219653</td>\n",
       "      <td>0.216994</td>\n",
       "      <td>0.219884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">bupa(345, 6)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.373103</td>\n",
       "      <td>0.365977</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.352184</td>\n",
       "      <td>0.376322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.392184</td>\n",
       "      <td>0.393333</td>\n",
       "      <td>0.386207</td>\n",
       "      <td>0.423678</td>\n",
       "      <td>0.403218</td>\n",
       "      <td>0.378161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.419080</td>\n",
       "      <td>0.432644</td>\n",
       "      <td>0.367816</td>\n",
       "      <td>0.425747</td>\n",
       "      <td>0.449655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">german(1000, 20)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.108480</td>\n",
       "      <td>0.077120</td>\n",
       "      <td>0.107840</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.073440</td>\n",
       "      <td>0.102240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.053360</td>\n",
       "      <td>0.041280</td>\n",
       "      <td>0.048640</td>\n",
       "      <td>0.041520</td>\n",
       "      <td>0.054560</td>\n",
       "      <td>0.046160</td>\n",
       "      <td>0.042400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.107760</td>\n",
       "      <td>0.108320</td>\n",
       "      <td>0.107360</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.108080</td>\n",
       "      <td>0.108800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ionosphere(351, 34)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.102273</td>\n",
       "      <td>0.133182</td>\n",
       "      <td>0.082727</td>\n",
       "      <td>0.129773</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.078182</td>\n",
       "      <td>0.130909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.058636</td>\n",
       "      <td>0.110909</td>\n",
       "      <td>0.101818</td>\n",
       "      <td>0.109545</td>\n",
       "      <td>0.113409</td>\n",
       "      <td>0.086364</td>\n",
       "      <td>0.094545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.056818</td>\n",
       "      <td>0.060909</td>\n",
       "      <td>0.046591</td>\n",
       "      <td>0.057955</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.047045</td>\n",
       "      <td>0.055227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">wdbc(569, 30)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.074126</td>\n",
       "      <td>0.065734</td>\n",
       "      <td>0.071748</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.062238</td>\n",
       "      <td>0.074126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.081119</td>\n",
       "      <td>0.081119</td>\n",
       "      <td>0.059021</td>\n",
       "      <td>0.082797</td>\n",
       "      <td>0.064615</td>\n",
       "      <td>0.056503</td>\n",
       "      <td>0.080979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.063497</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.064755</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.062238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">0.8</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">australian(690, 14)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.265896</td>\n",
       "      <td>0.309133</td>\n",
       "      <td>0.303815</td>\n",
       "      <td>0.322081</td>\n",
       "      <td>0.283237</td>\n",
       "      <td>0.277341</td>\n",
       "      <td>0.294220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.153873</td>\n",
       "      <td>0.175723</td>\n",
       "      <td>0.173873</td>\n",
       "      <td>0.178844</td>\n",
       "      <td>0.174682</td>\n",
       "      <td>0.164855</td>\n",
       "      <td>0.180578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.208092</td>\n",
       "      <td>0.219538</td>\n",
       "      <td>0.214220</td>\n",
       "      <td>0.225087</td>\n",
       "      <td>0.213873</td>\n",
       "      <td>0.213873</td>\n",
       "      <td>0.224740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">bupa(345, 6)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.356322</td>\n",
       "      <td>0.335402</td>\n",
       "      <td>0.315632</td>\n",
       "      <td>0.347816</td>\n",
       "      <td>0.321839</td>\n",
       "      <td>0.302759</td>\n",
       "      <td>0.346437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.279080</td>\n",
       "      <td>0.386437</td>\n",
       "      <td>0.356322</td>\n",
       "      <td>0.397701</td>\n",
       "      <td>0.273103</td>\n",
       "      <td>0.339080</td>\n",
       "      <td>0.385517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.402299</td>\n",
       "      <td>0.433103</td>\n",
       "      <td>0.428046</td>\n",
       "      <td>0.430345</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.426437</td>\n",
       "      <td>0.424138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">german(1000, 20)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.078160</td>\n",
       "      <td>0.050640</td>\n",
       "      <td>0.073760</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.050160</td>\n",
       "      <td>0.073280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.041520</td>\n",
       "      <td>0.042320</td>\n",
       "      <td>0.042560</td>\n",
       "      <td>0.042080</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>0.043520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.103840</td>\n",
       "      <td>0.105280</td>\n",
       "      <td>0.104320</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.105040</td>\n",
       "      <td>0.104640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ionosphere(351, 34)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.098864</td>\n",
       "      <td>0.077955</td>\n",
       "      <td>0.094773</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.074091</td>\n",
       "      <td>0.104545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.074318</td>\n",
       "      <td>0.092727</td>\n",
       "      <td>0.079091</td>\n",
       "      <td>0.095909</td>\n",
       "      <td>0.074318</td>\n",
       "      <td>0.066364</td>\n",
       "      <td>0.103864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.056818</td>\n",
       "      <td>0.057727</td>\n",
       "      <td>0.047045</td>\n",
       "      <td>0.063636</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.046136</td>\n",
       "      <td>0.061591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">wdbc(569, 30)</th>\n",
       "      <th>BP_Network</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.067832</td>\n",
       "      <td>0.056084</td>\n",
       "      <td>0.067552</td>\n",
       "      <td>0.048951</td>\n",
       "      <td>0.050909</td>\n",
       "      <td>0.067832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.079161</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0.072308</td>\n",
       "      <td>0.079021</td>\n",
       "      <td>0.090350</td>\n",
       "      <td>0.066154</td>\n",
       "      <td>0.072867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.070769</td>\n",
       "      <td>0.069650</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.069790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             SelfTraining1  \\\n",
       "label_rate dataset             classifier                    \n",
       "0.2        australian(690, 14) BP_Network         0.359538   \n",
       "                               DecisionTree       0.160231   \n",
       "                               NaiveBayes         0.179191   \n",
       "           bupa(345, 6)        BP_Network         0.464368   \n",
       "                               DecisionTree       0.354943   \n",
       "                               NaiveBayes         0.471264   \n",
       "           german(1000, 20)    BP_Network         0.180000   \n",
       "                               DecisionTree       0.032000   \n",
       "                               NaiveBayes         0.112000   \n",
       "           ionosphere(351, 34) BP_Network         0.250000   \n",
       "                               DecisionTree       0.164091   \n",
       "                               NaiveBayes         0.193182   \n",
       "           wdbc(569, 30)       BP_Network         0.125874   \n",
       "                               DecisionTree       0.157902   \n",
       "                               NaiveBayes         0.090909   \n",
       "0.4        australian(690, 14) BP_Network         0.543353   \n",
       "                               DecisionTree       0.186705   \n",
       "                               NaiveBayes         0.213873   \n",
       "           bupa(345, 6)        BP_Network         0.287356   \n",
       "                               DecisionTree       0.354253   \n",
       "                               NaiveBayes         0.459770   \n",
       "           german(1000, 20)    BP_Network         0.112000   \n",
       "                               DecisionTree       0.038560   \n",
       "                               NaiveBayes         0.112000   \n",
       "           ionosphere(351, 34) BP_Network         0.136364   \n",
       "                               DecisionTree       0.042955   \n",
       "                               NaiveBayes         0.102273   \n",
       "           wdbc(569, 30)       BP_Network         0.104895   \n",
       "                               DecisionTree       0.086713   \n",
       "                               NaiveBayes         0.062937   \n",
       "0.6        australian(690, 14) BP_Network         0.300578   \n",
       "                               DecisionTree       0.160000   \n",
       "                               NaiveBayes         0.202312   \n",
       "           bupa(345, 6)        BP_Network         0.379310   \n",
       "                               DecisionTree       0.431034   \n",
       "                               NaiveBayes         0.448276   \n",
       "           german(1000, 20)    BP_Network         0.068000   \n",
       "                               DecisionTree       0.053360   \n",
       "                               NaiveBayes         0.112000   \n",
       "           ionosphere(351, 34) BP_Network         0.102273   \n",
       "                               DecisionTree       0.058636   \n",
       "                               NaiveBayes         0.056818   \n",
       "           wdbc(569, 30)       BP_Network         0.076923   \n",
       "                               DecisionTree       0.081119   \n",
       "                               NaiveBayes         0.062937   \n",
       "0.8        australian(690, 14) BP_Network         0.265896   \n",
       "                               DecisionTree       0.153873   \n",
       "                               NaiveBayes         0.208092   \n",
       "           bupa(345, 6)        BP_Network         0.356322   \n",
       "                               DecisionTree       0.279080   \n",
       "                               NaiveBayes         0.402299   \n",
       "           german(1000, 20)    BP_Network         0.044000   \n",
       "                               DecisionTree       0.046800   \n",
       "                               NaiveBayes         0.112000   \n",
       "           ionosphere(351, 34) BP_Network         0.136364   \n",
       "                               DecisionTree       0.074318   \n",
       "                               NaiveBayes         0.056818   \n",
       "           wdbc(569, 30)       BP_Network         0.076923   \n",
       "                               DecisionTree       0.079161   \n",
       "                               NaiveBayes         0.069930   \n",
       "\n",
       "                                             SelfTraining1_init  \\\n",
       "label_rate dataset             classifier                         \n",
       "0.2        australian(690, 14) BP_Network              0.359538   \n",
       "                               DecisionTree            0.178150   \n",
       "                               NaiveBayes              0.184740   \n",
       "           bupa(345, 6)        BP_Network              0.464368   \n",
       "                               DecisionTree            0.417471   \n",
       "                               NaiveBayes              0.445747   \n",
       "           german(1000, 20)    BP_Network              0.200720   \n",
       "                               DecisionTree            0.041440   \n",
       "                               NaiveBayes              0.135120   \n",
       "           ionosphere(351, 34) BP_Network              0.245455   \n",
       "                               DecisionTree            0.230000   \n",
       "                               NaiveBayes              0.143409   \n",
       "           wdbc(569, 30)       BP_Network              0.092028   \n",
       "                               DecisionTree            0.106294   \n",
       "                               NaiveBayes              0.067273   \n",
       "0.4        australian(690, 14) BP_Network              0.333064   \n",
       "                               DecisionTree            0.201503   \n",
       "                               NaiveBayes              0.236763   \n",
       "           bupa(345, 6)        BP_Network              0.394253   \n",
       "                               DecisionTree            0.396092   \n",
       "                               NaiveBayes              0.449425   \n",
       "           german(1000, 20)    BP_Network              0.126400   \n",
       "                               DecisionTree            0.042240   \n",
       "                               NaiveBayes              0.110960   \n",
       "           ionosphere(351, 34) BP_Network              0.142500   \n",
       "                               DecisionTree            0.112273   \n",
       "                               NaiveBayes              0.086591   \n",
       "           wdbc(569, 30)       BP_Network              0.080000   \n",
       "                               DecisionTree            0.082098   \n",
       "                               NaiveBayes              0.058601   \n",
       "0.6        australian(690, 14) BP_Network              0.282312   \n",
       "                               DecisionTree            0.179769   \n",
       "                               NaiveBayes              0.229480   \n",
       "           bupa(345, 6)        BP_Network              0.373103   \n",
       "                               DecisionTree            0.392184   \n",
       "                               NaiveBayes              0.433333   \n",
       "           german(1000, 20)    BP_Network              0.108480   \n",
       "                               DecisionTree            0.041280   \n",
       "                               NaiveBayes              0.107760   \n",
       "           ionosphere(351, 34) BP_Network              0.133182   \n",
       "                               DecisionTree            0.110909   \n",
       "                               NaiveBayes              0.060909   \n",
       "           wdbc(569, 30)       BP_Network              0.074126   \n",
       "                               DecisionTree            0.081119   \n",
       "                               NaiveBayes              0.063497   \n",
       "0.8        australian(690, 14) BP_Network              0.309133   \n",
       "                               DecisionTree            0.175723   \n",
       "                               NaiveBayes              0.219538   \n",
       "           bupa(345, 6)        BP_Network              0.335402   \n",
       "                               DecisionTree            0.386437   \n",
       "                               NaiveBayes              0.433103   \n",
       "           german(1000, 20)    BP_Network              0.078160   \n",
       "                               DecisionTree            0.041520   \n",
       "                               NaiveBayes              0.103840   \n",
       "           ionosphere(351, 34) BP_Network              0.098864   \n",
       "                               DecisionTree            0.092727   \n",
       "                               NaiveBayes              0.057727   \n",
       "           wdbc(569, 30)       BP_Network              0.067832   \n",
       "                               DecisionTree            0.072727   \n",
       "                               NaiveBayes              0.070769   \n",
       "\n",
       "                                             SelfTraining2  \\\n",
       "label_rate dataset             classifier                    \n",
       "0.2        australian(690, 14) BP_Network         0.344624   \n",
       "                               DecisionTree       0.175029   \n",
       "                               NaiveBayes         0.187630   \n",
       "           bupa(345, 6)        BP_Network         0.446437   \n",
       "                               DecisionTree       0.387126   \n",
       "                               NaiveBayes         0.462759   \n",
       "           german(1000, 20)    BP_Network         0.143680   \n",
       "                               DecisionTree       0.036400   \n",
       "                               NaiveBayes         0.129920   \n",
       "           ionosphere(351, 34) BP_Network         0.266364   \n",
       "                               DecisionTree       0.186591   \n",
       "                               NaiveBayes         0.134318   \n",
       "           wdbc(569, 30)       BP_Network         0.081818   \n",
       "                               DecisionTree       0.092308   \n",
       "                               NaiveBayes         0.074965   \n",
       "0.4        australian(690, 14) BP_Network         0.451908   \n",
       "                               DecisionTree       0.180462   \n",
       "                               NaiveBayes         0.265896   \n",
       "           bupa(345, 6)        BP_Network         0.387816   \n",
       "                               DecisionTree       0.386437   \n",
       "                               NaiveBayes         0.470805   \n",
       "           german(1000, 20)    BP_Network         0.091280   \n",
       "                               DecisionTree       0.039760   \n",
       "                               NaiveBayes         0.107840   \n",
       "           ionosphere(351, 34) BP_Network         0.102045   \n",
       "                               DecisionTree       0.069773   \n",
       "                               NaiveBayes         0.069773   \n",
       "           wdbc(569, 30)       BP_Network         0.069650   \n",
       "                               DecisionTree       0.058601   \n",
       "                               NaiveBayes         0.060280   \n",
       "0.6        australian(690, 14) BP_Network         0.259538   \n",
       "                               DecisionTree       0.159306   \n",
       "                               NaiveBayes         0.217919   \n",
       "           bupa(345, 6)        BP_Network         0.365977   \n",
       "                               DecisionTree       0.393333   \n",
       "                               NaiveBayes         0.419080   \n",
       "           german(1000, 20)    BP_Network         0.077120   \n",
       "                               DecisionTree       0.048640   \n",
       "                               NaiveBayes         0.108320   \n",
       "           ionosphere(351, 34) BP_Network         0.082727   \n",
       "                               DecisionTree       0.101818   \n",
       "                               NaiveBayes         0.046591   \n",
       "           wdbc(569, 30)       BP_Network         0.065734   \n",
       "                               DecisionTree       0.059021   \n",
       "                               NaiveBayes         0.062937   \n",
       "0.8        australian(690, 14) BP_Network         0.303815   \n",
       "                               DecisionTree       0.173873   \n",
       "                               NaiveBayes         0.214220   \n",
       "           bupa(345, 6)        BP_Network         0.315632   \n",
       "                               DecisionTree       0.356322   \n",
       "                               NaiveBayes         0.428046   \n",
       "           german(1000, 20)    BP_Network         0.050640   \n",
       "                               DecisionTree       0.042320   \n",
       "                               NaiveBayes         0.105280   \n",
       "           ionosphere(351, 34) BP_Network         0.077955   \n",
       "                               DecisionTree       0.079091   \n",
       "                               NaiveBayes         0.047045   \n",
       "           wdbc(569, 30)       BP_Network         0.056084   \n",
       "                               DecisionTree       0.072308   \n",
       "                               NaiveBayes         0.069650   \n",
       "\n",
       "                                             SelfTraining2_init  Supervised  \\\n",
       "label_rate dataset             classifier                                     \n",
       "0.2        australian(690, 14) BP_Network              0.356994    0.323699   \n",
       "                               DecisionTree            0.177457    0.177457   \n",
       "                               NaiveBayes              0.173410    0.184971   \n",
       "           bupa(345, 6)        BP_Network              0.456552    0.459770   \n",
       "                               DecisionTree            0.390805    0.378161   \n",
       "                               NaiveBayes              0.443218    0.459770   \n",
       "           german(1000, 20)    BP_Network              0.209360    0.172000   \n",
       "                               DecisionTree            0.042480    0.029920   \n",
       "                               NaiveBayes              0.165040    0.096000   \n",
       "           ionosphere(351, 34) BP_Network              0.252727    0.250000   \n",
       "                               DecisionTree            0.234091    0.211818   \n",
       "                               NaiveBayes              0.142273    0.136364   \n",
       "           wdbc(569, 30)       BP_Network              0.095804    0.076923   \n",
       "                               DecisionTree            0.099441    0.107972   \n",
       "                               NaiveBayes              0.068252    0.076923   \n",
       "0.4        australian(690, 14) BP_Network              0.321040    0.236994   \n",
       "                               DecisionTree            0.197919    0.183815   \n",
       "                               NaiveBayes              0.240231    0.265896   \n",
       "           bupa(345, 6)        BP_Network              0.410575    0.367816   \n",
       "                               DecisionTree            0.414943    0.354713   \n",
       "                               NaiveBayes              0.455862    0.471264   \n",
       "           german(1000, 20)    BP_Network              0.135760    0.088000   \n",
       "                               DecisionTree            0.043040    0.036000   \n",
       "                               NaiveBayes              0.108960    0.108000   \n",
       "           ionosphere(351, 34) BP_Network              0.140227    0.136364   \n",
       "                               DecisionTree            0.119318    0.052500   \n",
       "                               NaiveBayes              0.086591    0.068182   \n",
       "           wdbc(569, 30)       BP_Network              0.079301    0.076923   \n",
       "                               DecisionTree            0.085035    0.056503   \n",
       "                               NaiveBayes              0.061259    0.055944   \n",
       "0.6        australian(690, 14) BP_Network              0.276763    0.289017   \n",
       "                               DecisionTree            0.178844    0.153988   \n",
       "                               NaiveBayes              0.218728    0.219653   \n",
       "           bupa(345, 6)        BP_Network              0.380000    0.310345   \n",
       "                               DecisionTree            0.386207    0.423678   \n",
       "                               NaiveBayes              0.432644    0.367816   \n",
       "           german(1000, 20)    BP_Network              0.107840    0.088000   \n",
       "                               DecisionTree            0.041520    0.054560   \n",
       "                               NaiveBayes              0.107360    0.108000   \n",
       "           ionosphere(351, 34) BP_Network              0.129773    0.068182   \n",
       "                               DecisionTree            0.109545    0.113409   \n",
       "                               NaiveBayes              0.057955    0.045455   \n",
       "           wdbc(569, 30)       BP_Network              0.071748    0.069930   \n",
       "                               DecisionTree            0.082797    0.064615   \n",
       "                               NaiveBayes              0.064755    0.062937   \n",
       "0.8        australian(690, 14) BP_Network              0.322081    0.283237   \n",
       "                               DecisionTree            0.178844    0.174682   \n",
       "                               NaiveBayes              0.225087    0.213873   \n",
       "           bupa(345, 6)        BP_Network              0.347816    0.321839   \n",
       "                               DecisionTree            0.397701    0.273103   \n",
       "                               NaiveBayes              0.430345    0.413793   \n",
       "           german(1000, 20)    BP_Network              0.073760    0.044000   \n",
       "                               DecisionTree            0.042560    0.042080   \n",
       "                               NaiveBayes              0.104320    0.104000   \n",
       "           ionosphere(351, 34) BP_Network              0.094773    0.090909   \n",
       "                               DecisionTree            0.095909    0.074318   \n",
       "                               NaiveBayes              0.063636    0.045455   \n",
       "           wdbc(569, 30)       BP_Network              0.067552    0.048951   \n",
       "                               DecisionTree            0.079021    0.090350   \n",
       "                               NaiveBayes              0.069930    0.069930   \n",
       "\n",
       "                                             TriTraining  TriTraining_init  \n",
       "label_rate dataset             classifier                                   \n",
       "0.2        australian(690, 14) BP_Network       0.347283          0.382081  \n",
       "                               DecisionTree     0.169942          0.177341  \n",
       "                               NaiveBayes       0.187514          0.183353  \n",
       "           bupa(345, 6)        BP_Network       0.445977          0.452644  \n",
       "                               DecisionTree     0.388736          0.432644  \n",
       "                               NaiveBayes       0.457701          0.452414  \n",
       "           german(1000, 20)    BP_Network       0.140640          0.205680  \n",
       "                               DecisionTree     0.038560          0.039600  \n",
       "                               NaiveBayes       0.098160          0.124800  \n",
       "           ionosphere(351, 34) BP_Network       0.255909          0.248636  \n",
       "                               DecisionTree     0.166364          0.222727  \n",
       "                               NaiveBayes       0.132955          0.138636  \n",
       "           wdbc(569, 30)       BP_Network       0.081259          0.097203  \n",
       "                               DecisionTree     0.084056          0.096224  \n",
       "                               NaiveBayes       0.075944          0.067552  \n",
       "0.4        australian(690, 14) BP_Network       0.465549          0.324624  \n",
       "                               DecisionTree     0.174335          0.198613  \n",
       "                               NaiveBayes       0.265896          0.236301  \n",
       "           bupa(345, 6)        BP_Network       0.380460          0.386667  \n",
       "                               DecisionTree     0.371724          0.391724  \n",
       "                               NaiveBayes       0.471494          0.452414  \n",
       "           german(1000, 20)    BP_Network       0.084400          0.132880  \n",
       "                               DecisionTree     0.038160          0.041920  \n",
       "                               NaiveBayes       0.108000          0.107040  \n",
       "           ionosphere(351, 34) BP_Network       0.099091          0.150000  \n",
       "                               DecisionTree     0.067273          0.107273  \n",
       "                               NaiveBayes       0.067955          0.087273  \n",
       "           wdbc(569, 30)       BP_Network       0.064755          0.079860  \n",
       "                               DecisionTree     0.057203          0.086014  \n",
       "                               NaiveBayes       0.059021          0.058042  \n",
       "0.6        australian(690, 14) BP_Network       0.250289          0.284509  \n",
       "                               DecisionTree     0.156647          0.176301  \n",
       "                               NaiveBayes       0.216994          0.219884  \n",
       "           bupa(345, 6)        BP_Network       0.352184          0.376322  \n",
       "                               DecisionTree     0.403218          0.378161  \n",
       "                               NaiveBayes       0.425747          0.449655  \n",
       "           german(1000, 20)    BP_Network       0.073440          0.102240  \n",
       "                               DecisionTree     0.046160          0.042400  \n",
       "                               NaiveBayes       0.108080          0.108800  \n",
       "           ionosphere(351, 34) BP_Network       0.078182          0.130909  \n",
       "                               DecisionTree     0.086364          0.094545  \n",
       "                               NaiveBayes       0.047045          0.055227  \n",
       "           wdbc(569, 30)       BP_Network       0.062238          0.074126  \n",
       "                               DecisionTree     0.056503          0.080979  \n",
       "                               NaiveBayes       0.062937          0.062238  \n",
       "0.8        australian(690, 14) BP_Network       0.277341          0.294220  \n",
       "                               DecisionTree     0.164855          0.180578  \n",
       "                               NaiveBayes       0.213873          0.224740  \n",
       "           bupa(345, 6)        BP_Network       0.302759          0.346437  \n",
       "                               DecisionTree     0.339080          0.385517  \n",
       "                               NaiveBayes       0.426437          0.424138  \n",
       "           german(1000, 20)    BP_Network       0.050160          0.073280  \n",
       "                               DecisionTree     0.043040          0.043520  \n",
       "                               NaiveBayes       0.105040          0.104640  \n",
       "           ionosphere(351, 34) BP_Network       0.074091          0.104545  \n",
       "                               DecisionTree     0.066364          0.103864  \n",
       "                               NaiveBayes       0.046136          0.061591  \n",
       "           wdbc(569, 30)       BP_Network       0.050909          0.067832  \n",
       "                               DecisionTree     0.066154          0.072867  \n",
       "                               NaiveBayes       0.069930          0.069790  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(results, values=None, index=['label_rate', 'dataset', 'classifier' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Supervised            16\n",
       "TriTraining           16\n",
       "SelfTraining1         15\n",
       "SelfTraining1_init     6\n",
       "SelfTraining2_init     3\n",
       "TriTraining_init       3\n",
       "SelfTraining2          1\n",
       "Name: Best, dtype: int64"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['Best'] = results.loc[:, ['TriTraining','SelfTraining1','TriTraining_init','SelfTraining1_init','SelfTraining2_init','SelfTraining2', 'Supervised']].idxmin(axis = 1)\n",
    "results['Tri'] = results.loc[:, ['TriTraining','TriTraining_init']].idxmin(axis = 1)\n",
    "results['Self1'] = results.loc[:, ['SelfTraining1','SelfTraining1_init']].idxmin(axis = 1)\n",
    "results['Self2'] = results.loc[:, ['SelfTraining2','SelfTraining2_init']].idxmin(axis = 1)\n",
    "results['Best'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('output.xlsx')\n",
    "results.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/8a/509eb6f58672288da9a5884e1cc7e90819bc8dbef501161c4b40a6a4e46b/openpyxl-2.5.12.tar.gz (173kB)\n",
      "\u001b[K    100% |████████████████████████████████| 174kB 7.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting jdcal (from openpyxl)\n",
      "  Downloading https://files.pythonhosted.org/packages/a0/38/dcf83532480f25284f3ef13f8ed63e03c58a65c9d3ba2a6a894ed9497207/jdcal-1.4-py2.py3-none-any.whl\n",
      "Collecting et_xmlfile (from openpyxl)\n",
      "  Downloading https://files.pythonhosted.org/packages/22/28/a99c42aea746e18382ad9fb36f64c1c1f04216f41797f2f0fa567da11388/et_xmlfile-1.0.1.tar.gz\n",
      "Building wheels for collected packages: openpyxl, et-xmlfile\n",
      "  Running setup.py bdist_wheel for openpyxl ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /jet/.cache/pip/wheels/95/b0/38/e5d13093b588f87177df648c06d07d4b7221f2c17d544cde4c\n",
      "  Running setup.py bdist_wheel for et-xmlfile ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /jet/.cache/pip/wheels/2a/77/35/0da0965a057698121fc7d8c5a7a9955cdbfb3cc4e2423cad39\n",
      "Successfully built openpyxl et-xmlfile\n",
      "Installing collected packages: jdcal, et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.0.1 jdcal-1.4 openpyxl-2.5.12\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
