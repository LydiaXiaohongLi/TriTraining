{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriTraining:\n",
    "    def __init__(self, classifier):\n",
    "        if sklearn.base.is_classifier(classifier):\n",
    "            self.classifiers = [sklearn.base.clone(classifier) for i in range(3)]\n",
    "        else:\n",
    "            self.classifiers = [sklearn.base.clone(classifier[i]) for i in range(3)]\n",
    "            \n",
    "    def fit(self, L_X, L_y, U_X):\n",
    "            \n",
    "        for i in range(3):\n",
    "            sample = sklearn.utils.resample(L_data, L_label)  # BootstrapSample(L)\n",
    "            self.classifiers[i].fit(*sample)  # Learn(Si)   \n",
    "        e_prime = [0.5]*3\n",
    "        l_prime = [0]*3\n",
    "        e = [0]*3\n",
    "        update = [False]*3\n",
    "        Li_X, Li_y = [[]]*3, [[]]*3#to save proxy labeled data\n",
    "        improve = True\n",
    "        self.iter = 0\n",
    "        \n",
    "        while improve:\n",
    "            self.iter += 1#count iterations \n",
    "            \n",
    "            for i in range(3):    \n",
    "                j, k = np.delete(np.array([0,1,2]),i)\n",
    "                update[i] = False\n",
    "                e[i] = self.measure_error(L_X, L_y, j, k)\n",
    "                if e[i] < e_prime[i]:\n",
    "                    U_y_j = self.classifiers[j].predict(U_data)\n",
    "                    U_y_k = self.classifiers[k].predict(U_data)\n",
    "                    Li_X[i] = U_X[U_y_j == U_y_k]#when two models agree on the label, save it\n",
    "                    Li_y[i] = U_y_j[U_y_j == U_y_k]\n",
    "                    if l_prime[i] == 0:#no updated before\n",
    "                        l_prime[i]  = int(e[i]/(e_prime[i] - e[i]) + 1)\n",
    "                    if l_prime[i] <len(Li_y[i]):\n",
    "                        if e[i]*len(Li_y[i])<e_prime[i] * l_prime[i]:\n",
    "                            update[i] = True\n",
    "                        elif l_prime[i] > e[i]/(e_prime[i] - e[i]):\n",
    "                            L_index = np.random.choice(len(Li_y[i]), int(e_prime[i] * l_prime[i]/e[i] -1))#subsample from proxy labeled data\n",
    "                            Li_X[i], Li_y[i] = Li_X[i][L_index], Li_y[i][L_index]\n",
    "                            update[i] = True\n",
    "             \n",
    "            for i in range(3):\n",
    "                if update[i]:\n",
    "                    self.classifiers[i].fit(np.append(L_X,Li_X[i],axis=0), np.append(L_y, Li_y[i], axis=0))#train the classifier on integrated dataset\n",
    "                    e_prime[i] = e[i]\n",
    "                    l_prime[i] = len(Li_y[i])\n",
    "    \n",
    "            if update == [False]*3:\n",
    "                improve = False#if no classifier was updated, no improvement\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = np.asarray([self.classifiers[i].predict(X) for i in range(3)])\n",
    "        pred[0][pred[1]==pred[2]] = pred[1][pred[1]==pred[2]]\n",
    "        return pred[0]\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        return sklearn.metrics.accuracy_score(y, self.predict(X))\n",
    "        \n",
    "    def measure_error(self, X, y, j, k):\n",
    "        j_pred = self.classifiers[j].predict(X)\n",
    "        k_pred = self.classifiers[k].predict(X)\n",
    "        wrong_index =np.logical_and(j_pred != y, k_pred==j_pred)#model_j and model_k make the same wrong prediction\n",
    "        #wrong_index =np.logical_and(j_pred != y_test, k_pred!=y_test)\n",
    "        return sum(wrong_index)/sum(j_pred == k_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(20, 10), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93600000000000005"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_data, L_label, U_data, X_test, y_test = data_process(dataset[d]['X'], dataset[d]['y'], r)\n",
    "\n",
    "classifiers = [sklearn.base.clone(classifier[i]) for i in classifier.keys()]\n",
    "\n",
    "#m = TriTraining(classifier['DecisionTree'])\n",
    "m = TriTraining(classifiers)\n",
    "\n",
    "m.fit(L_data, L_label, U_data)\n",
    "print(m.classifiers)\n",
    "m.score( X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfTraining:\n",
    "    def __init__(self, classifier):\n",
    "        self.classifier = sklearn.base.clone(classifier)\n",
    "    \n",
    "    def fit(self, L_X, L_y, U_X, tau):\n",
    "        improve =  True\n",
    "        self.iter = 0\n",
    "        while improve and len(U_X) !=0:\n",
    "            self.classifier.fit(L_X, L_y)\n",
    "            U_prob = self.classifier.predict_proba(U_X)\n",
    "            U_label = self.classifier.predict(U_X)\n",
    "            label_index = np.argmax(U_prob, axis = 1)>tau\n",
    "\n",
    "            if sum(label_index) ==0:\n",
    "                improve = False\n",
    "            self.iter += 1\n",
    "            L_X = np.append(L_X, U_X[label_index], axis=0)\n",
    "            L_y = np.append(L_y, U_label[label_index])\n",
    "            U_X = np.delete(U_X, np.where(label_index), axis=0)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.classifier.predict(X)\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        return sklearn.metrics.accuracy_score(y, self.predict(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriTrainingwDisagreement():\n",
    "\n",
    "    def __init__(self, classifier):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            classifier - classifier, with .fit, .predict API (refer to classifiers of sklearn)\n",
    "        \"\"\"\n",
    "        # Initialize\n",
    "        if sklearn.base.is_classifier(classifier):\n",
    "            self.clf = [sklearn.base.clone(classifier) for i in range(3)]\n",
    "        else:\n",
    "            self.clf = [sklearn.base.clone(classifier[i]) for i in range(3)]\n",
    "\n",
    "    def measure_error(self, j, k):\n",
    "        \"\"\"\n",
    "        args:\n",
    "                j - int, classifier index\n",
    "                k - int, classifier index\n",
    "        return:\n",
    "                float, classification_error\n",
    "        \"\"\"\n",
    "        y_predict_j = self.clf[j].predict(self.X_label)\n",
    "        y_predict_k = self.clf[k].predict(self.X_label)\n",
    "        return (1 - np.sum((y_predict_j == y_predict_k) & (y_predict_j == self.y_label)) / np.sum(y_predict_j == y_predict_k))\n",
    "\n",
    "    def fit(self, X_label, y_label, X_unlabel):\n",
    "        \"\"\"\n",
    "        args:\n",
    "                X_label - labeled train feature vector (ndarray of size, # of samples * # of features), features are numeric numbers\n",
    "                y_label - labeled train label vector (ndarray of size, # of samples), labels are numeric numbers\n",
    "                X_unlabel - test feature vector (ndarray of size, # of samples * # of features), features are numeric numbers\n",
    "        \"\"\"        \n",
    "\n",
    "        self.X_label = X_label\n",
    "        self.y_label = y_label\n",
    "\n",
    "        classification_error_current = [0.5, 0.5, 0.5]\n",
    "        classification_error = [0.5, 0.5, 0.5]\n",
    "        pseudo_label_size_current = [0, 0, 0]\n",
    "        pseudo_label_size = [0, 0, 0]\n",
    "        # pseudo_label_index used to compare and check if tri-training can be stopped, when two iterations have the same label_index, means tri-training can be stopped\n",
    "        X_pseudo_label_index = [[], [], []]\n",
    "        X_pseudo_label_index_current = [[], [], []]\n",
    "\n",
    "        feature_size = self.X_label.shape[1]\n",
    "\n",
    "        # Train each classifier with bootstrampped subset\n",
    "        for i in range(3):\n",
    "            X_resample, y_resample = sklearn.utils.resample(self.X_label, self.y_label)  # BootstrapSample(L)\n",
    "            self.clf[i].fit(X_resample, y_resample)  # Learn(Si)\n",
    "\n",
    "        iteration = 0\n",
    "        while (True):\n",
    "\n",
    "            update = [False, False, False]\n",
    "\n",
    "            iteration = iteration + 1\n",
    "            for i in range(3):\n",
    "                X_pseudo_label_index_current[i] = X_pseudo_label_index[i]\n",
    "\n",
    "            # Step3.1 Set Li = empty set, Li denotes the new pseudo label set determined by tri-training iteration for classifier i\n",
    "            # X_pseudo_label_index, contains the data record index (in the full unlabelled set) of the new pseudo label set determined by tri-training iteration for classifier i\n",
    "            # X_pseudo_label, contains the features for new pseudo label set determined by tri-training iteration for classifier i\n",
    "            # y_pseudo_label, contains the labels (not ground truth label, but pseudo label calculated by tri-training iteration) for new pseudo label set determined by tri-training iteration for classifier i\n",
    "            X_pseudo_label_index = [[], [], []]\n",
    "            X_pseudo_label = [[], [], []]\n",
    "            y_pseudo_label = [[], [], []]\n",
    "\n",
    "            # Step 3.2 Loop through all the data record in unlabelled set\n",
    "            for i in range(3):\n",
    "                j, k = np.delete(np.array([0, 1, 2]), i)\n",
    "                classification_error[i] = self.measure_error(j, k)\n",
    "                if classification_error[i] < classification_error_current[i]:\n",
    "                    # Step 3.2 If classifier j,k aggrees with the label for one data record, and not agree with classifier i, in unlabelled set,\n",
    "                    # then add the data record into Li                    \n",
    "                    y_predict_j = self.clf[j].predict(X_unlabel)\n",
    "                    y_predict_k = self.clf[k].predict(X_unlabel)\n",
    "                    y_predict_i = self.clf[i].predict(X_unlabel)\n",
    "                    y_pseudo_label[i] = y_predict_j[np.logical_and(y_predict_j==y_predict_k,y_predict_j!=y_predict_i)]\n",
    "                    X_pseudo_label_index[i] = np.where(np.logical_and(y_predict_j==y_predict_k,y_predict_j!=y_predict_i))\n",
    "                    \n",
    "                    pseudo_label_size[i] = len(X_pseudo_label_index[i])\n",
    "                    #print(\"classification_error: {}, classification_error_current: {}, pseudo_label_size: {}, pseudo_label_size_current: {}\".format(classification_error[i], classification_error_current[i], pseudo_label_size[i],pseudo_label_size_current[i]))\n",
    "\n",
    "                    if pseudo_label_size_current[i] == 0:\n",
    "                        pseudo_label_size_current[i] = math.floor(classification_error[i] / (classification_error_current[i] - classification_error[i]) + 1)\n",
    "                    if pseudo_label_size_current[i] < pseudo_label_size[i]:\n",
    "                        if ((classification_error[i] * pseudo_label_size[i]) < (classification_error_current[i] * pseudo_label_size_current[i])):\n",
    "                            update[i] = True\n",
    "                        elif pseudo_label_size_current[i] > (classification_error[i] / (classification_error_current[i] - classification_error[i])):\n",
    "                            resample_size = math.ceil(classification_error_current[i] * pseudo_label_size_current[i] / classification_error[i] - 1)\n",
    "                            X_pseudo_label_index[i], y_pseudo_label[i] = sklearn.utils.resample(X_pseudo_label_index[i],y_pseudo_label[i],replace=False,n_samples=resample_size)\n",
    "                            pseudo_label_size[i] = len(X_pseudo_label_index[i])\n",
    "                            update[i] = True\n",
    "\n",
    "            # Step 3.3 Train all the three classifiers with Li + original labelled data set\n",
    "            for i in range(3):\n",
    "                if update[i] == True:\n",
    "                    #print(\"number of pseudo labels added for classifier {} is: {}\".format(i,len(X_pseudo_label_index[i])))\n",
    "                    X_pseudo_label[i] = np.array(X_unlabel[X_pseudo_label_index[i]])\n",
    "                    self.clf[i].fit(np.concatenate((X_pseudo_label[i], self.X_label), axis=0),np.concatenate((np.array(y_pseudo_label[i]), self.y_label), axis=0))\n",
    "                    classification_error_current[i] = classification_error[i]\n",
    "                    pseudo_label_size_current[i] = pseudo_label_size[i]\n",
    "\n",
    "            # Stop tri-training process, if the pseudo label data set added in current tri-training iteration\n",
    "            # is the same for last tri-training iteration for all classifiers\n",
    "            if (np.array_equal(X_pseudo_label_index[0], X_pseudo_label_index_current[0]) & np.array_equal(X_pseudo_label_index[1], X_pseudo_label_index_current[1]) \n",
    "                    & np.array_equal(X_pseudo_label_index[2], X_pseudo_label_index_current[2])):\n",
    "                break\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        args:\n",
    "                X_test - test feature vector (ndarray of size, # of samples * # of features), features are numeric numbers\n",
    "        return:\n",
    "                array of size (# of test samples), with values as predicted label 1 or 0\n",
    "        \"\"\"\n",
    "        I = self.clf[0].predict(X_test)\n",
    "        J = self.clf[1].predict(X_test)\n",
    "        K = self.clf[2].predict(X_test)\n",
    "        I[J == K] = J[J == K]\n",
    "        return I\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        args:\n",
    "                X_test - test feature vector (ndarray of size, # of samples * # of features), features are numeric numbers\n",
    "                y_test - test label vector (ndarray of size, # of samples), labels are numeric numbers\n",
    "        return:\n",
    "                float, accuracy_score of predicted value by the tri-training (with disagreement) classifier against groud truth\n",
    "        \"\"\"\n",
    "        \n",
    "        return sklearn.metrics.accuracy_score(y_test, self.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(data, label, rate, test_rate=0.25):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size = test_rate, random_state=0)\n",
    "\n",
    "    rng = np.random.RandomState(0)#to make same index every time\n",
    "    labeled_index = rng.rand(len(y_train)) < rate#in training set, choose 20% as labeled data\n",
    "    unlabeled_index = np.logical_not(labeled_index)\n",
    "    L_data = X_train[labeled_index]#data of L\n",
    "    L_label = y_train[labeled_index]#lable of L\n",
    "    U_data = X_train[unlabeled_index]#data of U\n",
    "    return L_data, L_label, U_data, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = {}\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "\n",
    "classifier['DecisionTree'] = tree.DecisionTreeClassifier()\n",
    "classifier['BP_Network'] = MLPClassifier(solver='lbfgs', alpha=1e-3, hidden_layer_sizes=(20, 10), random_state=1)\n",
    "classifier['NaiveBayes'] = GaussianNB()\n",
    "# classifier['SGD'] = linear_model.SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "# classifier['SVM'] = svm.SVC(gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "\n",
    "data = np.loadtxt('australian.dat')[:, 0:14]\n",
    "label = np.loadtxt('australian.dat')[:, 14]\n",
    "dataset['australian'] = {'X': data, 'y':label}\n",
    "\n",
    "data = np.loadtxt('ionosphere.data', delimiter=',')[:, 0:34]\n",
    "label = np.loadtxt('ionosphere.data', delimiter=',')[:, 34]\n",
    "dataset['ionosphere'] = {'X': data, 'y':label}\n",
    "\n",
    "data = np.loadtxt('wdbc.data', delimiter=',')[:, 2:34]\n",
    "label = np.loadtxt('wdbc.data', delimiter=',')[:, 1]\n",
    "dataset['wdbc'] = {'X': data, 'y':label}\n",
    "\n",
    "data = np.loadtxt('bupa.data', delimiter=',')[:, :6]\n",
    "label = np.loadtxt('bupa.data', delimiter=',')[:, 6]\n",
    "dataset['bupa'] = {'X': data, 'y': label}\n",
    "\n",
    "data = np.loadtxt('german.data-numeric')[:, 0:20]\n",
    "label = np.loadtxt('german.data-numeric')[:, 20]\n",
    "dataset['german'] = {'X': data, 'y': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: australian (690, 14)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.2\n",
      "TriTraining test error 0.169075144509\n",
      "TriTraining Disagree test error 0.161560693642\n",
      "SelfTraining test error 0.161849710983\n",
      "Supervised test error 0.176878612717 \n",
      "\n",
      "dataset: australian (690, 14)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.4\n",
      "TriTraining test error 0.178034682081\n",
      "TriTraining Disagree test error 0.167919075145\n",
      "SelfTraining test error 0.186994219653\n",
      "Supervised test error 0.18612716763 \n",
      "\n",
      "dataset: australian (690, 14)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.6\n",
      "TriTraining test error 0.154335260116\n",
      "TriTraining Disagree test error 0.148265895954\n",
      "SelfTraining test error 0.160693641618\n",
      "Supervised test error 0.155780346821 \n",
      "\n",
      "dataset: australian (690, 14)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.8\n",
      "TriTraining test error 0.169075144509\n",
      "TriTraining Disagree test error 0.159537572254\n",
      "SelfTraining test error 0.159248554913\n",
      "Supervised test error 0.175433526012 \n",
      "\n",
      "dataset: australian (690, 14)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.2\n",
      "TriTraining test error 0.320231213873\n",
      "TriTraining Disagree test error 0.331213872832\n",
      "SelfTraining test error 0.549132947977\n",
      "Supervised test error 0.323699421965 \n",
      "\n",
      "dataset: australian (690, 14)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.4\n",
      "TriTraining test error 0.314739884393\n",
      "TriTraining Disagree test error 0.278612716763\n",
      "SelfTraining test error 0.543352601156\n",
      "Supervised test error 0.236994219653 \n",
      "\n",
      "dataset: australian (690, 14)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.6\n",
      "TriTraining test error 0.254624277457\n",
      "TriTraining Disagree test error 0.271098265896\n",
      "SelfTraining test error 0.300578034682\n",
      "Supervised test error 0.28901734104 \n",
      "\n",
      "dataset: australian (690, 14)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.8\n",
      "TriTraining test error 0.255202312139\n",
      "TriTraining Disagree test error 0.265317919075\n",
      "SelfTraining test error 0.265895953757\n",
      "Supervised test error 0.28323699422 \n",
      "\n",
      "dataset: australian (690, 14)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.2\n",
      "TriTraining test error 0.186705202312\n",
      "TriTraining Disagree test error 0.180057803468\n",
      "SelfTraining test error 0.179190751445\n",
      "Supervised test error 0.184971098266 \n",
      "\n",
      "dataset: australian (690, 14)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.4\n",
      "TriTraining test error 0.265895953757\n",
      "TriTraining Disagree test error 0.242774566474\n",
      "SelfTraining test error 0.21387283237\n",
      "Supervised test error 0.265895953757 \n",
      "\n",
      "dataset: australian (690, 14)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.6\n",
      "TriTraining test error 0.217630057803\n",
      "TriTraining Disagree test error 0.214161849711\n",
      "SelfTraining test error 0.202312138728\n",
      "Supervised test error 0.219653179191 \n",
      "\n",
      "dataset: australian (690, 14)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.8\n",
      "TriTraining test error 0.21387283237\n",
      "TriTraining Disagree test error 0.215895953757\n",
      "SelfTraining test error 0.208092485549\n",
      "Supervised test error 0.21387283237 \n",
      "\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.2\n",
      "TriTraining test error 0.161363636364\n",
      "TriTraining Disagree test error 0.198295454545\n",
      "SelfTraining test error 0.1625\n",
      "Supervised test error 0.210795454545 \n",
      "\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.4\n",
      "TriTraining test error 0.0755681818182\n",
      "TriTraining Disagree test error 0.0630681818182\n",
      "SelfTraining test error 0.0386363636364\n",
      "Supervised test error 0.0494318181818 \n",
      "\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.6\n",
      "TriTraining test error 0.08125\n",
      "TriTraining Disagree test error 0.0619318181818\n",
      "SelfTraining test error 0.0727272727273\n",
      "Supervised test error 0.105113636364 \n",
      "\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.8\n",
      "TriTraining test error 0.06875\n",
      "TriTraining Disagree test error 0.0693181818182\n",
      "SelfTraining test error 0.0670454545455\n",
      "Supervised test error 0.0732954545455 \n",
      "\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.2\n",
      "TriTraining test error 0.245454545455\n",
      "TriTraining Disagree test error 0.240909090909\n",
      "SelfTraining test error 0.25\n",
      "Supervised test error 0.25 \n",
      "\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.4\n",
      "TriTraining test error 0.0965909090909\n",
      "TriTraining Disagree test error 0.136931818182\n",
      "SelfTraining test error 0.136363636364\n",
      "Supervised test error 0.136363636364 \n",
      "\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.6\n",
      "TriTraining test error 0.0795454545455\n",
      "TriTraining Disagree test error 0.11875\n",
      "SelfTraining test error 0.102272727273\n",
      "Supervised test error 0.0681818181818 \n",
      "\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.8\n",
      "TriTraining test error 0.0715909090909\n",
      "TriTraining Disagree test error 0.0732954545455\n",
      "SelfTraining test error 0.136363636364\n",
      "Supervised test error 0.0909090909091 \n",
      "\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.2\n",
      "TriTraining test error 0.135795454545\n",
      "TriTraining Disagree test error 0.136931818182\n",
      "SelfTraining test error 0.193181818182\n",
      "Supervised test error 0.136363636364 \n",
      "\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.4\n",
      "TriTraining test error 0.0727272727273\n",
      "TriTraining Disagree test error 0.0761363636364\n",
      "SelfTraining test error 0.102272727273\n",
      "Supervised test error 0.0681818181818 \n",
      "\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.6\n",
      "TriTraining test error 0.0471590909091\n",
      "TriTraining Disagree test error 0.0488636363636\n",
      "SelfTraining test error 0.0568181818182\n",
      "Supervised test error 0.0454545454545 \n",
      "\n",
      "dataset: ionosphere (351, 34)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.8\n",
      "TriTraining test error 0.0471590909091\n",
      "TriTraining Disagree test error 0.0494318181818\n",
      "SelfTraining test error 0.0568181818182\n",
      "Supervised test error 0.0454545454545 \n",
      "\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.2\n",
      "TriTraining test error 0.0895104895105\n",
      "TriTraining Disagree test error 0.0807692307692\n",
      "SelfTraining test error 0.156643356643\n",
      "Supervised test error 0.105594405594 \n",
      "\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.4\n",
      "TriTraining test error 0.0562937062937\n",
      "TriTraining Disagree test error 0.0664335664336\n",
      "SelfTraining test error 0.091958041958\n",
      "Supervised test error 0.0562937062937 \n",
      "\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.6\n",
      "TriTraining test error 0.0559440559441\n",
      "TriTraining Disagree test error 0.0688811188811\n",
      "SelfTraining test error 0.079020979021\n",
      "Supervised test error 0.065034965035 \n",
      "\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.8\n",
      "TriTraining test error 0.0877622377622\n",
      "TriTraining Disagree test error 0.0590909090909\n",
      "SelfTraining test error 0.0762237762238\n",
      "Supervised test error 0.0947552447552 \n",
      "\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.2\n",
      "TriTraining test error 0.0797202797203\n",
      "TriTraining Disagree test error 0.0821678321678\n",
      "SelfTraining test error 0.125874125874\n",
      "Supervised test error 0.0769230769231 \n",
      "\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.4\n",
      "TriTraining test error 0.0699300699301\n",
      "TriTraining Disagree test error 0.0660839160839\n",
      "SelfTraining test error 0.104895104895\n",
      "Supervised test error 0.0769230769231 \n",
      "\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.6\n",
      "TriTraining test error 0.0615384615385\n",
      "TriTraining Disagree test error 0.0678321678322\n",
      "SelfTraining test error 0.0769230769231\n",
      "Supervised test error 0.0699300699301 \n",
      "\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.8\n",
      "TriTraining test error 0.0552447552448\n",
      "TriTraining Disagree test error 0.0618881118881\n",
      "SelfTraining test error 0.0769230769231\n",
      "Supervised test error 0.048951048951 \n",
      "\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.2\n",
      "TriTraining test error 0.0762237762238\n",
      "TriTraining Disagree test error 0.0706293706294\n",
      "SelfTraining test error 0.0909090909091\n",
      "Supervised test error 0.0769230769231 \n",
      "\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.4\n",
      "TriTraining test error 0.0601398601399\n",
      "TriTraining Disagree test error 0.0573426573427\n",
      "SelfTraining test error 0.0629370629371\n",
      "Supervised test error 0.0559440559441 \n",
      "\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.6\n",
      "TriTraining test error 0.0629370629371\n",
      "TriTraining Disagree test error 0.0646853146853\n",
      "SelfTraining test error 0.0629370629371\n",
      "Supervised test error 0.0629370629371 \n",
      "\n",
      "dataset: wdbc (569, 30)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.8\n",
      "TriTraining test error 0.0699300699301\n",
      "TriTraining Disagree test error 0.0706293706294\n",
      "SelfTraining test error 0.0699300699301\n",
      "Supervised test error 0.0699300699301 \n",
      "\n",
      "dataset: bupa (345, 6)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriTraining test error 0.416666666667\n",
      "TriTraining Disagree test error 0.390229885057\n",
      "SelfTraining test error 0.355747126437\n",
      "Supervised test error 0.376436781609 \n",
      "\n",
      "dataset: bupa (345, 6)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.4\n",
      "TriTraining test error 0.378735632184\n",
      "TriTraining Disagree test error 0.385632183908\n",
      "SelfTraining test error 0.354022988506\n",
      "Supervised test error 0.355747126437 \n",
      "\n",
      "dataset: bupa (345, 6)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.6\n",
      "TriTraining test error 0.364367816092\n",
      "TriTraining Disagree test error 0.361494252874\n",
      "SelfTraining test error 0.411494252874\n",
      "Supervised test error 0.429885057471 \n",
      "\n",
      "dataset: bupa (345, 6)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.8\n",
      "TriTraining test error 0.348850574713\n",
      "TriTraining Disagree test error 0.358045977011\n",
      "SelfTraining test error 0.289655172414\n",
      "Supervised test error 0.293103448276 \n",
      "\n",
      "dataset: bupa (345, 6)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.2\n",
      "TriTraining test error 0.443103448276\n",
      "TriTraining Disagree test error 0.454597701149\n",
      "SelfTraining test error 0.459770114943\n",
      "Supervised test error 0.459770114943 \n",
      "\n",
      "dataset: bupa (345, 6)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.4\n",
      "TriTraining test error 0.377011494253\n",
      "TriTraining Disagree test error 0.384482758621\n",
      "SelfTraining test error 0.287356321839\n",
      "Supervised test error 0.367816091954 \n",
      "\n",
      "dataset: bupa (345, 6)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.6\n",
      "TriTraining test error 0.356896551724\n",
      "TriTraining Disagree test error 0.336206896552\n",
      "SelfTraining test error 0.379310344828\n",
      "Supervised test error 0.310344827586 \n",
      "\n",
      "dataset: bupa (345, 6)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.8\n",
      "TriTraining test error 0.314367816092\n",
      "TriTraining Disagree test error 0.323563218391\n",
      "SelfTraining test error 0.35632183908\n",
      "Supervised test error 0.32183908046 \n",
      "\n",
      "dataset: bupa (345, 6)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.2\n",
      "TriTraining test error 0.451724137931\n",
      "TriTraining Disagree test error 0.443103448276\n",
      "SelfTraining test error 0.471264367816\n",
      "Supervised test error 0.459770114943 \n",
      "\n",
      "dataset: bupa (345, 6)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.4\n",
      "TriTraining test error 0.469540229885\n",
      "TriTraining Disagree test error 0.448275862069\n",
      "SelfTraining test error 0.459770114943\n",
      "Supervised test error 0.471264367816 \n",
      "\n",
      "dataset: bupa (345, 6)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.6\n",
      "TriTraining test error 0.410344827586\n",
      "TriTraining Disagree test error 0.433333333333\n",
      "SelfTraining test error 0.448275862069\n",
      "Supervised test error 0.367816091954 \n",
      "\n",
      "dataset: bupa (345, 6)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.8\n",
      "TriTraining test error 0.431609195402\n",
      "TriTraining Disagree test error 0.429310344828\n",
      "SelfTraining test error 0.402298850575\n",
      "Supervised test error 0.413793103448 \n",
      "\n",
      "dataset: german (1000, 20)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.2\n",
      "TriTraining test error 0.0358\n",
      "TriTraining Disagree test error 0.0366\n",
      "SelfTraining test error 0.0306\n",
      "Supervised test error 0.0302 \n",
      "\n",
      "dataset: german (1000, 20)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.4\n",
      "TriTraining test error 0.0352\n",
      "TriTraining Disagree test error 0.0332\n",
      "SelfTraining test error 0.0404\n",
      "Supervised test error 0.036 \n",
      "\n",
      "dataset: german (1000, 20)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.6\n",
      "TriTraining test error 0.0432\n",
      "TriTraining Disagree test error 0.0364\n",
      "SelfTraining test error 0.053\n",
      "Supervised test error 0.0542 \n",
      "\n",
      "dataset: german (1000, 20)\n",
      "classifier: DecisionTree\n",
      "label_rate: 0.8\n",
      "TriTraining test error 0.0428\n",
      "TriTraining Disagree test error 0.0368\n",
      "SelfTraining test error 0.047\n",
      "Supervised test error 0.042 \n",
      "\n",
      "dataset: german (1000, 20)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.2\n",
      "TriTraining test error 0.132\n",
      "TriTraining Disagree test error 0.1834\n",
      "SelfTraining test error 0.18\n",
      "Supervised test error 0.172 \n",
      "\n",
      "dataset: german (1000, 20)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.4\n",
      "TriTraining test error 0.0894\n",
      "TriTraining Disagree test error 0.1142\n",
      "SelfTraining test error 0.112\n",
      "Supervised test error 0.088 \n",
      "\n",
      "dataset: german (1000, 20)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.6\n",
      "TriTraining test error 0.0686\n",
      "TriTraining Disagree test error 0.0912\n",
      "SelfTraining test error 0.068\n",
      "Supervised test error 0.088 \n",
      "\n",
      "dataset: german (1000, 20)\n",
      "classifier: BP_Network\n",
      "label_rate: 0.8\n",
      "TriTraining test error 0.0536\n",
      "TriTraining Disagree test error 0.0648\n",
      "SelfTraining test error 0.044\n",
      "Supervised test error 0.044 \n",
      "\n",
      "dataset: german (1000, 20)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.2\n",
      "TriTraining test error 0.0982\n",
      "TriTraining Disagree test error 0.1182\n",
      "SelfTraining test error 0.112\n",
      "Supervised test error 0.096 \n",
      "\n",
      "dataset: german (1000, 20)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.4\n",
      "TriTraining test error 0.108\n",
      "TriTraining Disagree test error 0.1036\n",
      "SelfTraining test error 0.112\n",
      "Supervised test error 0.108 \n",
      "\n",
      "dataset: german (1000, 20)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.6\n",
      "TriTraining test error 0.108\n",
      "TriTraining Disagree test error 0.106\n",
      "SelfTraining test error 0.112\n",
      "Supervised test error 0.108 \n",
      "\n",
      "dataset: german (1000, 20)\n",
      "classifier: NaiveBayes\n",
      "label_rate: 0.8\n",
      "TriTraining test error 0.1056\n",
      "TriTraining Disagree test error 0.1024\n",
      "SelfTraining test error 0.112\n",
      "Supervised test error 0.104 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = None\n",
    "\n",
    "for d in dataset:\n",
    "    for c in classifier:\n",
    "        for r in [0.2, 0.4, 0.6, 0.8]:        \n",
    "            print('dataset:', d, dataset[d]['X'].shape)\n",
    "            print('classifier:', c)\n",
    "            print('label_rate:', r)\n",
    "            error = np.zeros([4,20])\n",
    "            for i in range(20):#average on 20 data splits\n",
    "                L_data, L_label, U_data, X_test, y_test = data_process(dataset[d]['X'], dataset[d]['y'], r)\n",
    "                m1 = TriTraining(classifier[c])\n",
    "                m1.fit(L_data, L_label, U_data)\n",
    "                m2 = TriTrainingwDisagreement(classifier[c])\n",
    "                m2.fit(L_data, L_label, U_data)\n",
    "                m3 = SelfTraining(classifier[c])\n",
    "                m3.fit(L_data, L_label, U_data, tau = 0.6)\n",
    "                m4 = sklearn.base.clone(classifier[c])\n",
    "                m4.fit(L_data, L_label)\n",
    "                error[0, i] = 1-m1.score(X_test, y_test)\n",
    "                error[1, i] = 1-m2.score(X_test, y_test)\n",
    "                error[2, i] = 1-m3.score(X_test, y_test)\n",
    "                error[3, i] = 1-m4.score(X_test, y_test)\n",
    "                \n",
    "            e = np.mean(error, axis = 1)\n",
    "\n",
    "            print('TriTraining test error', e[0])\n",
    "            print('TriTraining Disagree test error', e[1])\n",
    "            print('SelfTraining test error', e[2])\n",
    "            print('Supervised test error', e[3],'\\n')\n",
    "            \n",
    "            methods = ['Tri', 'Self', 'Sup']\n",
    "            test_info = {'dataset': d+str(dataset[d]['X'].shape), 'classifier': c, 'label_rate': r}\n",
    "            errors = {'TriTraining': e[0], 'TriTraining Disagree': e[1], 'SelfTraining': e[2], 'Supervised': e[3]}#, 'Best': methods[np.argmin(e)]}#'\n",
    "            if results is None:\n",
    "                results = pd.DataFrame([{**test_info, **errors}])\n",
    "            else:\n",
    "                results.loc[len(results.index)] = {**test_info, **errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SelfTraining</th>\n",
       "      <th>Supervised</th>\n",
       "      <th>TriTraining</th>\n",
       "      <th>TriTraining Disagree</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_rate</th>\n",
       "      <th>classifier</th>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">0.2</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">BP_Network</th>\n",
       "      <th>australian(690, 14)</th>\n",
       "      <td>0.549133</td>\n",
       "      <td>0.323699</td>\n",
       "      <td>0.320231</td>\n",
       "      <td>0.331214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bupa(345, 6)</th>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.443103</td>\n",
       "      <td>0.454598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>german(1000, 20)</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.183400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionosphere(351, 34)</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.245455</td>\n",
       "      <td>0.240909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdbc(569, 30)</th>\n",
       "      <td>0.125874</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.082168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">DecisionTree</th>\n",
       "      <th>australian(690, 14)</th>\n",
       "      <td>0.161850</td>\n",
       "      <td>0.176879</td>\n",
       "      <td>0.169075</td>\n",
       "      <td>0.161561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bupa(345, 6)</th>\n",
       "      <td>0.355747</td>\n",
       "      <td>0.376437</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.390230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>german(1000, 20)</th>\n",
       "      <td>0.030600</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.036600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionosphere(351, 34)</th>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.210795</td>\n",
       "      <td>0.161364</td>\n",
       "      <td>0.198295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdbc(569, 30)</th>\n",
       "      <td>0.156643</td>\n",
       "      <td>0.105594</td>\n",
       "      <td>0.089510</td>\n",
       "      <td>0.080769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">NaiveBayes</th>\n",
       "      <th>australian(690, 14)</th>\n",
       "      <td>0.179191</td>\n",
       "      <td>0.184971</td>\n",
       "      <td>0.186705</td>\n",
       "      <td>0.180058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bupa(345, 6)</th>\n",
       "      <td>0.471264</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.451724</td>\n",
       "      <td>0.443103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>german(1000, 20)</th>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.098200</td>\n",
       "      <td>0.118200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionosphere(351, 34)</th>\n",
       "      <td>0.193182</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.135795</td>\n",
       "      <td>0.136932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdbc(569, 30)</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076224</td>\n",
       "      <td>0.070629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">0.4</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">BP_Network</th>\n",
       "      <th>australian(690, 14)</th>\n",
       "      <td>0.543353</td>\n",
       "      <td>0.236994</td>\n",
       "      <td>0.314740</td>\n",
       "      <td>0.278613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bupa(345, 6)</th>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.367816</td>\n",
       "      <td>0.377011</td>\n",
       "      <td>0.384483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>german(1000, 20)</th>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.114200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionosphere(351, 34)</th>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.096591</td>\n",
       "      <td>0.136932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdbc(569, 30)</th>\n",
       "      <td>0.104895</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.066084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">DecisionTree</th>\n",
       "      <th>australian(690, 14)</th>\n",
       "      <td>0.186994</td>\n",
       "      <td>0.186127</td>\n",
       "      <td>0.178035</td>\n",
       "      <td>0.167919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bupa(345, 6)</th>\n",
       "      <td>0.354023</td>\n",
       "      <td>0.355747</td>\n",
       "      <td>0.378736</td>\n",
       "      <td>0.385632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>german(1000, 20)</th>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.033200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionosphere(351, 34)</th>\n",
       "      <td>0.038636</td>\n",
       "      <td>0.049432</td>\n",
       "      <td>0.075568</td>\n",
       "      <td>0.063068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdbc(569, 30)</th>\n",
       "      <td>0.091958</td>\n",
       "      <td>0.056294</td>\n",
       "      <td>0.056294</td>\n",
       "      <td>0.066434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">NaiveBayes</th>\n",
       "      <th>australian(690, 14)</th>\n",
       "      <td>0.213873</td>\n",
       "      <td>0.265896</td>\n",
       "      <td>0.265896</td>\n",
       "      <td>0.242775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bupa(345, 6)</th>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.471264</td>\n",
       "      <td>0.469540</td>\n",
       "      <td>0.448276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>german(1000, 20)</th>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.103600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionosphere(351, 34)</th>\n",
       "      <td>0.102273</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0.076136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdbc(569, 30)</th>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.055944</td>\n",
       "      <td>0.060140</td>\n",
       "      <td>0.057343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">0.6</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">BP_Network</th>\n",
       "      <th>australian(690, 14)</th>\n",
       "      <td>0.300578</td>\n",
       "      <td>0.289017</td>\n",
       "      <td>0.254624</td>\n",
       "      <td>0.271098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bupa(345, 6)</th>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.356897</td>\n",
       "      <td>0.336207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>german(1000, 20)</th>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.091200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionosphere(351, 34)</th>\n",
       "      <td>0.102273</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.079545</td>\n",
       "      <td>0.118750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdbc(569, 30)</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.067832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">DecisionTree</th>\n",
       "      <th>australian(690, 14)</th>\n",
       "      <td>0.160694</td>\n",
       "      <td>0.155780</td>\n",
       "      <td>0.154335</td>\n",
       "      <td>0.148266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bupa(345, 6)</th>\n",
       "      <td>0.411494</td>\n",
       "      <td>0.429885</td>\n",
       "      <td>0.364368</td>\n",
       "      <td>0.361494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>german(1000, 20)</th>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.036400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionosphere(351, 34)</th>\n",
       "      <td>0.072727</td>\n",
       "      <td>0.105114</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.061932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdbc(569, 30)</th>\n",
       "      <td>0.079021</td>\n",
       "      <td>0.065035</td>\n",
       "      <td>0.055944</td>\n",
       "      <td>0.068881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">NaiveBayes</th>\n",
       "      <th>australian(690, 14)</th>\n",
       "      <td>0.202312</td>\n",
       "      <td>0.219653</td>\n",
       "      <td>0.217630</td>\n",
       "      <td>0.214162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bupa(345, 6)</th>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.367816</td>\n",
       "      <td>0.410345</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>german(1000, 20)</th>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionosphere(351, 34)</th>\n",
       "      <td>0.056818</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.047159</td>\n",
       "      <td>0.048864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdbc(569, 30)</th>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.064685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">0.8</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">BP_Network</th>\n",
       "      <th>australian(690, 14)</th>\n",
       "      <td>0.265896</td>\n",
       "      <td>0.283237</td>\n",
       "      <td>0.255202</td>\n",
       "      <td>0.265318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bupa(345, 6)</th>\n",
       "      <td>0.356322</td>\n",
       "      <td>0.321839</td>\n",
       "      <td>0.314368</td>\n",
       "      <td>0.323563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>german(1000, 20)</th>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.053600</td>\n",
       "      <td>0.064800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionosphere(351, 34)</th>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.071591</td>\n",
       "      <td>0.073295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdbc(569, 30)</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.048951</td>\n",
       "      <td>0.055245</td>\n",
       "      <td>0.061888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">DecisionTree</th>\n",
       "      <th>australian(690, 14)</th>\n",
       "      <td>0.159249</td>\n",
       "      <td>0.175434</td>\n",
       "      <td>0.169075</td>\n",
       "      <td>0.159538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bupa(345, 6)</th>\n",
       "      <td>0.289655</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0.348851</td>\n",
       "      <td>0.358046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>german(1000, 20)</th>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>0.036800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionosphere(351, 34)</th>\n",
       "      <td>0.067045</td>\n",
       "      <td>0.073295</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.069318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdbc(569, 30)</th>\n",
       "      <td>0.076224</td>\n",
       "      <td>0.094755</td>\n",
       "      <td>0.087762</td>\n",
       "      <td>0.059091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">NaiveBayes</th>\n",
       "      <th>australian(690, 14)</th>\n",
       "      <td>0.208092</td>\n",
       "      <td>0.213873</td>\n",
       "      <td>0.213873</td>\n",
       "      <td>0.215896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bupa(345, 6)</th>\n",
       "      <td>0.402299</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.431609</td>\n",
       "      <td>0.429310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>german(1000, 20)</th>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.102400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionosphere(351, 34)</th>\n",
       "      <td>0.056818</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.047159</td>\n",
       "      <td>0.049432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdbc(569, 30)</th>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.070629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             SelfTraining  Supervised  \\\n",
       "label_rate classifier   dataset                                         \n",
       "0.2        BP_Network   australian(690, 14)      0.549133    0.323699   \n",
       "                        bupa(345, 6)             0.459770    0.459770   \n",
       "                        german(1000, 20)         0.180000    0.172000   \n",
       "                        ionosphere(351, 34)      0.250000    0.250000   \n",
       "                        wdbc(569, 30)            0.125874    0.076923   \n",
       "           DecisionTree australian(690, 14)      0.161850    0.176879   \n",
       "                        bupa(345, 6)             0.355747    0.376437   \n",
       "                        german(1000, 20)         0.030600    0.030200   \n",
       "                        ionosphere(351, 34)      0.162500    0.210795   \n",
       "                        wdbc(569, 30)            0.156643    0.105594   \n",
       "           NaiveBayes   australian(690, 14)      0.179191    0.184971   \n",
       "                        bupa(345, 6)             0.471264    0.459770   \n",
       "                        german(1000, 20)         0.112000    0.096000   \n",
       "                        ionosphere(351, 34)      0.193182    0.136364   \n",
       "                        wdbc(569, 30)            0.090909    0.076923   \n",
       "0.4        BP_Network   australian(690, 14)      0.543353    0.236994   \n",
       "                        bupa(345, 6)             0.287356    0.367816   \n",
       "                        german(1000, 20)         0.112000    0.088000   \n",
       "                        ionosphere(351, 34)      0.136364    0.136364   \n",
       "                        wdbc(569, 30)            0.104895    0.076923   \n",
       "           DecisionTree australian(690, 14)      0.186994    0.186127   \n",
       "                        bupa(345, 6)             0.354023    0.355747   \n",
       "                        german(1000, 20)         0.040400    0.036000   \n",
       "                        ionosphere(351, 34)      0.038636    0.049432   \n",
       "                        wdbc(569, 30)            0.091958    0.056294   \n",
       "           NaiveBayes   australian(690, 14)      0.213873    0.265896   \n",
       "                        bupa(345, 6)             0.459770    0.471264   \n",
       "                        german(1000, 20)         0.112000    0.108000   \n",
       "                        ionosphere(351, 34)      0.102273    0.068182   \n",
       "                        wdbc(569, 30)            0.062937    0.055944   \n",
       "0.6        BP_Network   australian(690, 14)      0.300578    0.289017   \n",
       "                        bupa(345, 6)             0.379310    0.310345   \n",
       "                        german(1000, 20)         0.068000    0.088000   \n",
       "                        ionosphere(351, 34)      0.102273    0.068182   \n",
       "                        wdbc(569, 30)            0.076923    0.069930   \n",
       "           DecisionTree australian(690, 14)      0.160694    0.155780   \n",
       "                        bupa(345, 6)             0.411494    0.429885   \n",
       "                        german(1000, 20)         0.053000    0.054200   \n",
       "                        ionosphere(351, 34)      0.072727    0.105114   \n",
       "                        wdbc(569, 30)            0.079021    0.065035   \n",
       "           NaiveBayes   australian(690, 14)      0.202312    0.219653   \n",
       "                        bupa(345, 6)             0.448276    0.367816   \n",
       "                        german(1000, 20)         0.112000    0.108000   \n",
       "                        ionosphere(351, 34)      0.056818    0.045455   \n",
       "                        wdbc(569, 30)            0.062937    0.062937   \n",
       "0.8        BP_Network   australian(690, 14)      0.265896    0.283237   \n",
       "                        bupa(345, 6)             0.356322    0.321839   \n",
       "                        german(1000, 20)         0.044000    0.044000   \n",
       "                        ionosphere(351, 34)      0.136364    0.090909   \n",
       "                        wdbc(569, 30)            0.076923    0.048951   \n",
       "           DecisionTree australian(690, 14)      0.159249    0.175434   \n",
       "                        bupa(345, 6)             0.289655    0.293103   \n",
       "                        german(1000, 20)         0.047000    0.042000   \n",
       "                        ionosphere(351, 34)      0.067045    0.073295   \n",
       "                        wdbc(569, 30)            0.076224    0.094755   \n",
       "           NaiveBayes   australian(690, 14)      0.208092    0.213873   \n",
       "                        bupa(345, 6)             0.402299    0.413793   \n",
       "                        german(1000, 20)         0.112000    0.104000   \n",
       "                        ionosphere(351, 34)      0.056818    0.045455   \n",
       "                        wdbc(569, 30)            0.069930    0.069930   \n",
       "\n",
       "                                             TriTraining  TriTraining Disagree  \n",
       "label_rate classifier   dataset                                                 \n",
       "0.2        BP_Network   australian(690, 14)     0.320231              0.331214  \n",
       "                        bupa(345, 6)            0.443103              0.454598  \n",
       "                        german(1000, 20)        0.132000              0.183400  \n",
       "                        ionosphere(351, 34)     0.245455              0.240909  \n",
       "                        wdbc(569, 30)           0.079720              0.082168  \n",
       "           DecisionTree australian(690, 14)     0.169075              0.161561  \n",
       "                        bupa(345, 6)            0.416667              0.390230  \n",
       "                        german(1000, 20)        0.035800              0.036600  \n",
       "                        ionosphere(351, 34)     0.161364              0.198295  \n",
       "                        wdbc(569, 30)           0.089510              0.080769  \n",
       "           NaiveBayes   australian(690, 14)     0.186705              0.180058  \n",
       "                        bupa(345, 6)            0.451724              0.443103  \n",
       "                        german(1000, 20)        0.098200              0.118200  \n",
       "                        ionosphere(351, 34)     0.135795              0.136932  \n",
       "                        wdbc(569, 30)           0.076224              0.070629  \n",
       "0.4        BP_Network   australian(690, 14)     0.314740              0.278613  \n",
       "                        bupa(345, 6)            0.377011              0.384483  \n",
       "                        german(1000, 20)        0.089400              0.114200  \n",
       "                        ionosphere(351, 34)     0.096591              0.136932  \n",
       "                        wdbc(569, 30)           0.069930              0.066084  \n",
       "           DecisionTree australian(690, 14)     0.178035              0.167919  \n",
       "                        bupa(345, 6)            0.378736              0.385632  \n",
       "                        german(1000, 20)        0.035200              0.033200  \n",
       "                        ionosphere(351, 34)     0.075568              0.063068  \n",
       "                        wdbc(569, 30)           0.056294              0.066434  \n",
       "           NaiveBayes   australian(690, 14)     0.265896              0.242775  \n",
       "                        bupa(345, 6)            0.469540              0.448276  \n",
       "                        german(1000, 20)        0.108000              0.103600  \n",
       "                        ionosphere(351, 34)     0.072727              0.076136  \n",
       "                        wdbc(569, 30)           0.060140              0.057343  \n",
       "0.6        BP_Network   australian(690, 14)     0.254624              0.271098  \n",
       "                        bupa(345, 6)            0.356897              0.336207  \n",
       "                        german(1000, 20)        0.068600              0.091200  \n",
       "                        ionosphere(351, 34)     0.079545              0.118750  \n",
       "                        wdbc(569, 30)           0.061538              0.067832  \n",
       "           DecisionTree australian(690, 14)     0.154335              0.148266  \n",
       "                        bupa(345, 6)            0.364368              0.361494  \n",
       "                        german(1000, 20)        0.043200              0.036400  \n",
       "                        ionosphere(351, 34)     0.081250              0.061932  \n",
       "                        wdbc(569, 30)           0.055944              0.068881  \n",
       "           NaiveBayes   australian(690, 14)     0.217630              0.214162  \n",
       "                        bupa(345, 6)            0.410345              0.433333  \n",
       "                        german(1000, 20)        0.108000              0.106000  \n",
       "                        ionosphere(351, 34)     0.047159              0.048864  \n",
       "                        wdbc(569, 30)           0.062937              0.064685  \n",
       "0.8        BP_Network   australian(690, 14)     0.255202              0.265318  \n",
       "                        bupa(345, 6)            0.314368              0.323563  \n",
       "                        german(1000, 20)        0.053600              0.064800  \n",
       "                        ionosphere(351, 34)     0.071591              0.073295  \n",
       "                        wdbc(569, 30)           0.055245              0.061888  \n",
       "           DecisionTree australian(690, 14)     0.169075              0.159538  \n",
       "                        bupa(345, 6)            0.348851              0.358046  \n",
       "                        german(1000, 20)        0.042800              0.036800  \n",
       "                        ionosphere(351, 34)     0.068750              0.069318  \n",
       "                        wdbc(569, 30)           0.087762              0.059091  \n",
       "           NaiveBayes   australian(690, 14)     0.213873              0.215896  \n",
       "                        bupa(345, 6)            0.431609              0.429310  \n",
       "                        german(1000, 20)        0.105600              0.102400  \n",
       "                        ionosphere(351, 34)     0.047159              0.049432  \n",
       "                        wdbc(569, 30)           0.069930              0.070629  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(results, values=None, index=['label_rate', 'classifier' ,'dataset' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TriTraining Disagree    18\n",
       "TriTraining             15\n",
       "SelfTraining            14\n",
       "Supervised              13\n",
       "Name: Best, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['Best'] = results.loc[:, ['TriTraining','SelfTraining', 'TriTraining Disagree', 'Supervised']].idxmin(axis = 1)\n",
    "results['Best'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
